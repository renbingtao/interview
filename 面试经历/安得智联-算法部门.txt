讲下主导得项目及情况

在数据分析平台中，你是作为主开还是什么角色

这个项目最大的特点是什么

你们是如何埋点的

你们的sdk会把数据推送到后台，那如何保证接口的稳定性

消费kafka时如何避免重复消费的问题
消费者每次消费完都会手动提交offset。此外消费者自己也要做好幂等，即一锁二判三更新

如何分区的

你们kafka的配置是怎样的，如何维护机器及copy的分配规则

每个topic有多少个partition，配置多少个partition

有出现过写入阻塞的情况吗
写入阻塞是指生产者向kafka发送消息时，发送被卡住，表现为send方法高延迟或者超时。常见原因可能是broker的磁盘空间不足，或者生产者的参数acks设置为-1或者all，需要所有副本都确认才返回成功。如果副本和leader的偏移量差距过大，会被踢出ISR。如果ISR的数量少于阈值，broker会拒绝写入
其他原因也可能是网络抖动，cpu内存负载过高

你们的ELK是基于开源框架部署的吗

你们的集群部署在自己的机房还是云上

你们项目用zookeeper实现了配置中心，这个zk是和kafka共用同一个zookeeper吗

简单说一下zk的选举逻辑

为什么不使用eruka或者nacos做注册中心

在博监项目中，你主要负责哪一块呢

你们的项目是怎么部署的

你们的脱敏查询是在哪一个维度脱敏的？数据库还是接口？脱敏的具体实现。批量导出也要做脱敏吗

讲下通过itsm单配置限流

批量导出的量级是多大

jdbc查询数据库用的什么方式？滚动地获取数据还是流式的获取

分页慢的问题怎么解决
