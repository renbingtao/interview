
zookeeper=文件系统+通知机制
文件系统：zk存储和管理大家都关心的数据
通知机制：zk接收观察者的注册，一旦存储的数据发生变化，就通知观察者

zk特点
zk集群由1个leader和多个follower组成，leader负责读写请求，follower负责读请求
集群中只要有半数以上（刚好半数不行）节点存活，zk就能对外提供服务。所以zk适合安装在奇数个数的服务器上
全局数据一致：每个节点的数据相同
更新请求顺序执行，即来自同一个客户端的请求按照发送顺序依次执行
数据更新原子性：一次数据更新要么成功，要么失败
实时性：在一段时间内，client能读取到最新的数据

数据结构
与unix很类似，都是树形结构，每个znode默认能存储1mb的数据（这意味着zk不能存储海量数据，只能存储配置信息）

应用场景
统一命名服务：分布式环境下，经常需要对应用/服务进行统一命名，方便管理
统一配置管理：分布式环境下，一般要求一个集群下所有节点的配置信息一致；对配置修改后，希望尽快同步到各个节点。实现：znode节点保存配置信息，各个客户端监听这个znode
统一集群管理：分布式环境下，实时掌握节点的状态是很重要的，可以根据节点状态进行实时调整。实现：将节点信息写入znode，监听该node即可获取它的实时状态变化
服务器节点动态上下线
软负载均衡等

节点类型
持久化/非持久化：在客户端与服务端断开连接后，持久化节点仍会存在，而非持久化节点会删除。临时节点不能有子节点。节点类型创建后确定，无法修改
有序号/无序号：序号类似于数据库的自增主键，由zk维护。新建一个已存在的节点，若该节点是无序号则会报错，有序号则会更新序号

监听机制原理
1.新建客户端并和服务端建立连接。客户端会创建两个线程：一个负责网络通信（connect），一个负责监听（listener）
2.通过connect线程将注册的监听时间发送给zk
3.zk将注册的监听事件添加到监听器列表
4.zk监听到有数据或路径变化时，就将这个消息发送给listener线程
5.线程内部调用process方法
注册是一次性的，如果需要继续监听要重新注册

写数据
如果客户端连接的是follower，且是写请求，则follower把请求转发给leader。如果客户端连接的是leader，则leader直接处理
leader收到写请求后，自己先执行，然后让其他follower执行，等待返回。超过半数（不能是刚好半数）节点（包括leader自己）都写完并应答后，leader向客户端返回成功（或返回给follower，由follower返回给客户端）
其他未写完的follower继续写，写完应答给leader

znode数据版本
新建znode节点并设置值后，值的版本（version字段）为0（get -s /path来查看版本）
通过set更新值后，version++
zk本身不会保留老版本的值
版本号可用于乐观锁的实现
// 乐观锁示例：只有版本匹配时才更新，类似cas
zk.setData("/node", newData, expectedVersion);


zk常用的监听事件
事件类型	                触发条件	                                        常用监听API
NodeCreated	            被监听的节点被创建（之前不存在）	                exists(path, true)
NodeDeleted	            被监听的节点被删除	                            exists(path, true) 或 getData(path, true)
NodeDataChanged	        被监听的节点数据发生变更	                        exists(path, true) 或 getData(path, true)
NodeChildrenChanged	    被监听的节点的子节点列表发生变化（增/删子节点）	    getChildren(path, true)

NodeDataChanged事件无法获取变更前的值，如有需求，需要在代码中手动维护

zk分布式锁
手动实现
1.抢锁：多个客户端在某个特定znode下创建临时有序节点，zk可以保证顺序性
2.客户端创建成功后，判断自己是否是该znode节点下的最小节点，是则获取到锁；不是则监听上一个节点（exists，判断是否为删除事件）
3.获取到锁的客户端执行完任务后，删除临时节点（下一个节点会监听到事件，然后重复第二步判断）
这种方案会导致客户端一直等待，直到获取锁。此外是公平锁
实际工作
使用curator框架。原理和自己手动实现类似（临时有序节点+watch）

=====================zk选举机制=====================
zk集群通常由奇数个节点组成
投票阶段：
自我推荐：节点启动时，会先给自己投一票。票包含两个关键信息：服务器id和该节点见证的最新事务id（也叫zxid，是一种逻辑时钟）
广播投票：每个节点将自己的票发送给其他节点

服务器id：不能重复，和myid一致
zxid：通常是64位的数字，高位epoch表示选举周期，低位表示递增的计数器。每当zk完成一轮选举（也可以说投票），epoch就会递增。节点投票时会优先考虑zxid更大的节点；相同时选举服务器id更大的节点

zk第一次启动
每个服务器启动时，都发起一轮选举。比如集群有5个节点
1.myid=1的节点a先启动，发起投票，并给自己投一票。总票数不足3，a处于looking状态
2.myid=2的节点b启动，又发起投票（意味着epoch++），1和2分别给自己投票并【交换投票信息】，a节点发现b节点的id更大，改投票给b。ab处于looking状态
3.myid=3的节点c启动，发起投票，并获取ab+自己的票，超过半数，赢得选举。ab处于following，c处于leading
4.myid=4的节点d启动，发起投票，abc非looking状态，不会重新投票。交换投票信息后，d改为following状态。e节点同理
节点发起投票时，实际上将自己的currentEpoch+1并作为新一轮投票的epoch

zk非第一次启动
服务器发起leader选举的两种情况：初始化启动；运行期间无法和leader取得联系
发起选举时，leader可能存在（网络分区）也可能不存在（挂了）
leader存在时，发起投票的机器会被告知leader信息，并成为follower
leader不存在时，发起投票

选举leader规则：
1.epoch大的直接胜出
2.epoch相同，zxid大的胜出
3.zxid相同，myid大的胜出

=====================zab=====================
消息广播
leader接收客户端的请求，生成一个zxid
将请求及zxid广播给所有follower（follower内部有一个FIFO队列）
follower接收后，先写入磁盘（不执行），并返回ack
leader收到超过半数的ack后，提交事务，广播commit消息
follower收到commit消息后，提交上一条消息

