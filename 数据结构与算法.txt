
========================表、栈和队列========================

表（list）比较简单，跳过

栈（stack）
栈是限制插入和删除只能在一个位置上进行的表（list），该位置是表的末端，叫做栈的顶（top）。对栈的基本操作有push（进栈）和pop（出栈）。栈有时又叫做LIFO（后进先出）表。栈一般的模型是，存在某个元素位于栈顶，而该元素是唯一的可见元素
栈的实现
由于栈是一个表，因此任何实现表的方法都能实现栈，包括ArrayList 和LinkedList，前者更加流行。栈很可能是计算机科学中在数组之后的最基本的数据机构
栈的应用
1.平衡符号
编译器检查程序的语法错误时，经常检查符号是否成对出现，比如[()]是合法的，([)]是非法的。
这个算法用到一个栈：创建一个空栈，读入全部字符，若字符为开放符号，比如"("，则push；若字符是封闭符号，栈为空则报错，否则pop，若pop出的符号不是对应的开放符号。在结尾，若栈为非空则报错
2.后缀表达式
计算4.99*1.06+5.99+6.99*1.06，可将操作书写如下：4.99 1.06 * 5.99 + 6.99 1.06 * +
这个记法叫做后缀（或逆波兰）记法。对于后缀表达式的计算，可用栈解决：遇到一个数就push，遇到计算符号就pop出两个，将计算结果push，最后栈中只有一个元素，即结果
中缀到后缀的转换
假设有中缀表达式（也叫做标准形式的表达式）：a+b*c+(d*e+f)*g，将其变成后缀表达式，结果为abc*+de*f+g*+ 过程复杂跳过
3.方法调用
调用新方法时，主调例程的所有局部变量都要存储，包括当前位置也要存储，以便新方法运行完后向哪里跳转。这个问题和平衡符号很类似，方法调用和方法返回类似于开括号和闭括号

队列（queue）
队列也是表，但使用队列时，插入在一端进行，删除在另一端进行
队列的基本操作包括：enqueue（入队），在表的末端（或队尾）插入一个元素；dequeue（出队），删除并返回表的开头（或队头）的元素
队列的应用
访计算机用户访问文件服务器（file server）中的文件是按照先到先得的原则访问，因此其数据结构是一个队列

========================树========================

树的遍历
private void listAll(int depth){
    printName(depth)
    if(isDirectory()){
        foreach(file c:directory){
            c.listAll(depth+1)
        }
    }
}
上述遍历策略称为【先序遍历】，即对节点的处理是在它的诸多儿子节点被处理之前进行的
另一种遍历方法时【后序遍历】，即先处理儿子节点，再处理本节点

二叉查找树
对于树中的每个节点X，它的左子树所有项的值小于X中的项，右子树中所有项的值大于X中的项。【中序遍历】：先处理左子树，然后当前节点，最后处理右子树

伸展树
本质上是二叉查找树，它的特点是把最近访问的节点移动到根节点，后续访问相同节点时能减少时间开销，所以很适合缓存

平衡二叉树
最矮的树和最高的树高度差最多为1，即平衡因子=左子树高度-右子树高度的绝对值<=1。不平衡时，再判断不平衡的子树是左节点还是右节点插入导致的不平衡。
LL型(平衡因子=2且子树的平衡因子=1)右旋，RR同理左旋；LR型（平衡因子=2且子树的平衡因子=-1）左右旋，同理RL型右左旋。
查询时间复杂度O（log n），n为节点总数
适用于插入删除少，查询多的场景

红黑树
由于平衡二叉树对高度差的要求很高，需要频繁旋转，插入性能差，因此定义了红黑树，减少旋转次数。最高的树的高度最多是最矮的树的高度的2倍。
规则：是搜索树（左根右）。每个节点为红或者黑。根及叶子节点为黑，这里的叶子节点指的是最下面的节点下的null节点。连续两个节点不能为红。根到叶子节点（null）的黑色节点总数一致。
规则总结为：左根右，根叶黑，不红红，黑路同
插入时，默认插入红色节点。当不满足规则时，进行判定：叔叔节点是红还是黑？如果是红色，则父叔爷三个节点变色（红变黑，黑变红），同时爷爷节点变为插入节点，重复上述操作；如果是黑色，进行LL、RR等旋转（参考平衡二叉树），然后对旋转点及中心点进行变色

B树
B树为M叉查找树，即节点最多有M个子节点，阶为M（二叉树的阶为2）
节点的扇出在M/2到M之间
所有叶子节点的高度一致；内部节点包含关键字、记录指针、指向下一节点的指针
所有节点的关键字都是从小到大排序

B+树
B树的升级版，内部节点不保存记录指针，使得扇出变大，树矮胖。适合内存有限

========================散列========================

散列表的实现常常叫做散列（hashing），是一种以常数平均时间执行插入、删除和查找的技术，但是不支持排序相关操作

散列函数
一个相对好的散列函数示例
public static int hash(String key,int tableSize){
    int hashVal=0;
    for(int i=0;i<key.length();i++){
        hashVal=37*hashVal+key.charAt(i);
    }
    hashVal%=tableSize;
    if(hashVal<0)
        hashVal+=tableSize;
    return hashVal;
}
计算时hashVal可能溢出，可能导致出现负数，因此末尾进行了负数处理
接下来讨论出现hash冲突时解决方法

分离链接法
即将冲突的元素都保存在一个表中，采用头插（不光是简单，而且新插入的元素最有可能不久被访问）

开放定址法
分离链接法的缺点是使用链表，分配地址需要时间，导致速度减慢。另一种方案是尝试另外一些单元，直到找出空的单元为止
h0(x),h1(x),h2(x),...相继被诗选，其中hi(x)=(hash(x)+f(i)) mod TableSize，且f(0)=0。f是冲突解决方法
由于所有数据都放在表内，因此这种方案所需要的表比分离链接法的表要大，一般来说负载因子要小于0.5。我们把这种表称为探测散列表

线性探测法
f是i的线性函数，典型为f(i)=i。举例：hash表size为10，hash(key)=key%10。插入一下键值对：89,18,49,58,69
89放在索引9
18放在索引8
插入49时产生冲突，它被放在写一个空闲地址，即索引0
插入58时和18冲突，试图放入索引0，又和49冲突，放入索引1
插入69和89、49、58冲突，放入索引2
有点：空间利用率高
缺点：即使表相对较空，占据的单元也会形成一些区块，这种结果称为一次聚集，导致查找和插入效率变低

平方探测法
平方探测法是消除线性探测中一次聚集问题的冲突解决办法，流行选择时f(i)=i2。仍然用上面的例子举例
89放在索引9
18放在索引8
49冲突，i=0，放在索引0
58和18冲突。i=0和49冲突。i=1时（58+1*1）mod 10=9，和89冲突。i=2时（58+2*2）mod 10=2，即放在索引2
69和89冲突。i=0和49冲突。i=1时（69+1*1）mod 10=0冲突。i=2时（69+2*2）mod 10=3，即放在索引3
优点：避免聚集现象，避免局部空间过度拥挤
缺点：负载因子很高时，探测序列会变长，性能变差；负载因子小于0.5时不保证一定能找到位置，需要扩容

双散列
流行公式是f(i)=i*hash2(x)。hash2函数选择得不好将会是灾难性的。hash2(x)=R-(x mod R)是一个良好的函数，其中R是小于tablesize的素数（质数）
优点：均匀分布，减少冲突的概率
缺点：计算成本高；复杂，对第二个散列函数的要求高

========================优先队列（堆）========================

我们给队列中的每个元素都分配一个数字来标记优先级，这样我们就可以在一个集合中访问优先级最高的元素并进行查找删除操作了
优先队列至少要包含两种操作：insert和deleteMin。后者的工作是找出、返回并删除优先队列中最小的元素

二叉堆
我们可以使用二叉堆来实现优先队列，且这种实现非常普遍。后续简称堆

堆的结构性质
一个完全二叉树。可以用数组来表示、存储：按照从上到下，从左到右的顺序保存在数组中，根节点放在下标1。对于数组中任意下标i的元素，其左儿子下标为2i，右儿子下标为2i+1，父亲下标为[i/2]（向下取整）
        A
    B       C
D      E  F   G
上述二叉树用数组保存为[空,A,B,C,D,E,F,G,空,空]

堆序性质
我们需要找到最小元，则最小元应该在根上。若考虑任意子树也是一个堆，则任意节点应该小于它的所有后裔。基于此，我们得到堆序性质：在一个堆中，对于每一个节点X，X的父亲的关键字小于（或等于）X中的关键字，根节点除外。即从根出发，到叶子节点，是递增的
根据堆序性质，最小元总可以在根找到，因此我们以常数时间得到附加操作findMin
这种称为小根堆，最小堆。若根节点为最大，依次递减，则为大根堆

insert操作
为将一个元素X插入到堆中，需要在下一个可用位置创建一个空穴，否则堆将不是完全树。如果X放入空穴后不破坏堆的序，则插入完成。否则把空穴的父节点的元素移入空穴，这样空穴就向着根的方向前进一步，依次类推，直到X能被放入空穴。时间复杂度为O(logN)。这种策略叫做【上虑】

deleteMin操作
找出最小元是容易的，难的是删除它。删除一个最小元时，要在根节点建立一个空穴。由于堆少了一个元素，因此要移动最后一个元素X，若X可以被放入空穴，则deleteMin操作完成，不过一般不可能，因此将空穴的两个儿子中的较小者移入空穴，则此时空穴向下推了一层。重复上述过程直到X可以被放入空穴。即从根开始，根据最小儿子的路径，将X插入到正确的位置。时间复杂度为O(logN)。这种策略叫做【下虑】

其他的堆操作
最小堆在求最大元方面没有帮助。一个堆蕴含的排序信息很少。关于最大元，唯一知道的信息是该元素在树叶上，但是一个堆中一半的元素都在树叶上，因此该信息价值不大。如果想要知道元素在什么地方，则除了堆之外，还需要使用其他数据结构，比如散列表。我们假设通过其他方法得知每一个元素的位置，那么下列的操作开销会变小：

decreaseKey降低关键字的值
decreaseKey(p,a)操作降低位置（下标）p处的项的值，降幅为a，由于可能破坏堆序性质，必须通过上滤对堆进行调整

increaseKey降低关键字的值
同理，通过下滤调整

delete删除
delete(p)删除堆中位置p上的节点，首先执行decreaseKey(p,+∞)，然后deleteMin()

buildHeap构建堆
自顶向下
适用于逐个插入元素。对每个元素，执行插入堆，上滤。时间复杂度时O(NlogN)

自底向上
适用于已知所有元素后批量构建堆。假设堆有N个元素，直接构建一个堆（此时不满足堆序性质），从最后一个非叶子节点开始（位置为N/2或向下取整），向前遍历所有节点，对节点执行下滤。时间复杂度为O(N)

优先队列的应用
选择问题，即有N个元素，找出第k大的
算法一：将N个元素读入数组，调用buildHeap（耗时N），执行k次deleteMin（耗时klogN），即可得到第k小的元素，时间复杂度为O(N+klogN)，k=N/2时，为O(NlogN)。只需要把小根堆改成大根堆即可得到第k大的
算法二：将前k个元素读入数组并调用buildHeap构建大根堆（耗时k），对剩下的N-k个元素检查（耗时1），大于堆的最大值则删除并插入新值（耗时(N-k)*logk），总耗时O(Nlogk)j，k=N/2时为O(NlogN)

========================排序========================

堆排序
将包含N个元素的数组构建成二叉堆，耗时O(NlogN)，然后执行N次deleteMin，即最小的元素依次离开堆，将它们记录到新建的数组中，即可得到N个元素的排序
上面算法的问题是使用了附加的数组，内存消耗翻倍。解决方案：每次deleteMin后，堆的大小-1，可以把最后删除的元素放入堆中最后的单元。如果是小根堆，通过这种策略，在最后一次deleteMin后，数组中的元素是递减的。改成大根堆即可实现递增
举例：堆有6个元素，第一次deleteMin删除a1，把a1放在位置6；第二次deleteMin删除a2，把a2放入位置5
举例：输入的序列为[31,41,59,26,53,58,97]，得到堆如下
            97
    53              59
26      41      58      31
数组为[null,97,53,59,26,41,58,31,null,null,null]

进行第一次deleteMin后，结果如下
            59
    53              58
26      41      31      (97)
其中97已删除，并放入最后一个单元
数组为[null,59,53,58,26,41,31,97,null,null,null]

归并排序
这个算法的基本操作是合并两个已排序的表。基本的合并算法是取两个输入数组A和B，一个输出数组C，以及三个计数器a，b，c，分别对应ABC的开始位置，将a、b中的较小者（比如是a）复制到c，并将a的计数器+1，当AB任意一个表使用完，将另一个表的剩余部分复制到C中
该算法是典型的分治策略，它将问题【分】成一些小的问题然后递归求解，而【治】的阶段则将分阶段得到的各答案修补到一起。时间复杂度是O(NlogN)

贪心算法与动态规划的区别
贪心算法追求局部最优解，划分的每个子问题都最优，但不能保证全局最优
动态规划：将问题分解为重复的子问题，每次都寻找左右子问题解中最优的解，一步步得到全局最优解。重复的子问题可以记录下来，避免重复计算
比如钱币分为1、3、4元，要6元，贪心先拿4，再拿两个1；而动态规划拿两个3

分治法
与动态规划类似，将大问题分解为小问题，但这些小问题是独立的
