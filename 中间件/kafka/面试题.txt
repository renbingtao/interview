
=============================kafka和rabbitmq、activemq、rocketmq的区别=============================
1.kafka主要支持发布订阅模式，其他三种则支持点对点和发布订阅模式
2.kafka吞吐量达百万，其他三者吞吐量较低
3.kafka使用简单，易于部署，但实现高级功能需要复杂配置。其他三者提供了更多功能，但也增加开发的复杂度
4.功能区别
                优先队列        延迟队列        死信队列        消费模式        事务消息
kafka           不支持         不支持             不           拉               支持
rocketmq        支持           支持             支持          推和拉             支持
rabbitmq        支持          插件支持            支持         推和拉          支持

=============================kafka为何块=============================

1.批量发送。用户是一条一条发送消息，但kafka将多个消息打包成一个批次一起发
2.异步发送，消息被放到本地的缓存中，就返回了，不必等待。消息数量达到阈值或时间达到阈值时，后台线程会发送
3.消息压缩
4.零拷贝
rocketmq为了支持各种高级特性（延迟队列、顺序消息、事务消息等），对可靠性要求很高，不允许批量发送
kafka诞生的背景是大数据、日志处理，可以丢一点

零拷贝
普通的读写流程如下
1.用户read发起系统调用，用户态切换到内核态，通过DMA技术将数据从磁盘拷贝到【内核缓冲区】            ---DMA做的
2.DMA完成后，发起一个中断，CPU将【内核缓冲区】中的内容拷贝到【用户缓冲区】                       ---CPU做的
3.线程切换回用户态，逻辑处理
4.将用户态中的内容拷贝到【socket缓冲区】（内核态）                                             ---CPU做的
5.将【socket缓冲区】的数据拷贝到网卡                                                         ---DMA做的
6.网卡发送数据
上面的过程中，数据经历了4次拷贝，所谓零拷贝，就是通过各种方法减少拷贝的次数，比如mmap，sendfile，dma，direct io等

DMA
正常来说，数据拷贝是需要CPU参与的：从外设（如磁盘）读取到cpu寄存器，再写入内存。DMA技术允许外设直接与内存交换数据，仅在开始和结束时通知CPU

mmap
数据从磁盘拷贝到【内核缓冲区】（DMA），【映射】到用户缓冲区（无需拷贝），【内核缓冲区】拷贝到【socket缓冲区】（CPU），【socket缓冲区】再拷贝到网卡（DMA）。一共两次DMA，一次CPU
允许程序像访问内存一样访问文件，无需read和write。
通过系统调用mmap()将磁盘映射到进程的虚拟地址，当程序读写映射的内存区域时，触发缺页异常，操作系统会将文件加载或写回
mmap在使用时必须指定映射的大小，因此不适合变长的文件。rocketmq就是采用的这种方式

sendFile
如果只是传输数据，不对数据做修改，则可以通过sendFile的方式，这也是kafka采用的方式
在linux 2.4之前，和mmap是一样的（2+1）
2.4之后：磁盘拷贝到【内核缓冲区】（DMA），【内核缓冲区】拷贝到网卡（DMA gather copy，需要网卡的硬件支持），只有2次DM拷贝，省去了CPU拷贝
上面的4次拷贝，有两次是浪费的：用户空间<-->内核空间。零拷贝就是把这两次拷贝绕过，应用程序可以把磁盘中的数据从内核直接发送到网卡，即磁盘->内核->网卡，零拷贝是针对用户空间而言的
对于生产者而言，sendfile直接拷贝数据发送给网卡，导致程序无法获取消息内容，无法做消息加工处理，这限制了kafka的功能。所以RocketMQ选择了更慢的mmap技术

高水位
高水位（High Watermark，简称 HW） 是一个关键概念，用于标识分区中已完成复制的消息边界，确保数据的可靠性和一致性。
高水位代表分区中所有副本（包括 leader 和 follower）都已成功同步的最高消息位置。
对于消费者而言，只能消费高水位以下的消息（即 offset 小于高水位的消息），这保证了消费者只能看到已完成复制的、不会丢失的消息。
Kafka 的日志清理机制（如删除旧日志段）只会清理高水位以下的过期数据，确保未完成同步的消息不会被过早删除。

LEO
LEO 是每个副本（Replica） 本地日志中最后一条消息的下一个位置（偏移量）。
例如：若一个副本的日志中包含偏移量为 0、1、2 的消息，则其 LEO 为 3，表示下一条写入的消息将使用偏移量 3。
LEO 是每个副本独立维护的变量，不同副本的 LEO 可能因同步进度不同而存在差异。
LEO 直观反映了某个副本当前的日志写入进度，数值越大表示该副本包含的消息越多。
分区的高水位（HW）由该分区所有 ISR（同步副本集） 中最小的 LEO 决定。即：
HW = min(所有 ISR 副本的 LEO)
Follower 副本通过对比自身 LEO 与 Leader 副本的 LEO，判断需要从 Leader 同步哪些消息（从自身 LEO 位置开始拉取）。
