
=============================kafka核心概念=============================
topic
消息的逻辑分类，类似于数据库的表，由一个或多个partition组成

partition
每个分区内的消息是有序的（按写入顺序排列，用偏移量 offset 标识位置），但不同分区之间的消息无序
分区会分散存储在 Kafka 集群的不同 Broker 节点上，实现负载均衡
可通过增加分区数量提升 Topic 的吞吐量（分区数越多，并行处理能力越强）
每个分区实际上是一个文件夹，里面包含3个文件:xxx.index,xxx.log,xxx.timeindex
index记录了offset->物理文件位置
log记录了消息内容
timeindex记录了时间戳->offset，比如(1620000000000, 100), (1620000001000, 200), ...
因此在一个分区内，消息是顺序的

segment
一个partition由多个segment组成，每个segment由.log和.index文件组成
Segment 文件以该段中第一条消息的偏移量命名（64 位数字），例如：00000000000000012345.log（包含从偏移量 12345 开始的消息）

offset
每个分区中的消息都有一个唯一的 offset（从 0 开始的递增整数），用于标识消息在分区中的位置
消费者通过记录 offset 来跟踪自己的消费进度（如 “已消费到 offset=100 的消息”）

replication
为了保证可靠性，引入了副本机制，每个分区可以配置多个副本，其中一个为leader，其他为follower，一般来说分布在不同的broker上
leader处理客户端请求；follower被动复制leader的数据，不处理客户端请求。消费者只能从leader消费消息，而不能从follower消费
ISR：In-Sync Replicas，同步副本集合，与领导者保持同步的副本（包括领导者自身）
leader故障时，ISR中的副本有资格被选举为新leader

broker
kafka实例

key
生产者发送消息时，可以指定key。key是用来决定消息被分配到哪个partition的。kafka会对key进行hash计算，并根据结果将消息映射到某个partition
这保证了相同 key 的消息会被分配到同一个分区（除非分区数量变更或重新分区）
这一特性对需要顺序消费的场景至关重要：由于单个分区内的消息是严格按顺序存储和消费的，相同 key 的消息进入同一分区后，消费者就能按发送顺序处理它们
key为null时，消息会随机分配到不同partition

zookeeper作用
2.8及以前，zk用来协调各个broker，包括broker的注册与发现，partition leader选举，保存元数据（topic，partition，replication）
2.8后引入KRaft模式，最终取代zk
4.0完全移除zk模式

consumer
mq不会主动推送消息，而是消费者主动拉取消息。消费消息时可以指定partition（发送时也可以指定）

consumer group
由一个或多个consumer组成，这些消费者共同订阅一个或多个topic。对于某个partition，同一时刻只能被消费者组内的一个消费者消费（但可以被其他消费者组的消费者同时消费），但一个消费者可以消费多个partition
组内一个消费者可以消费多个partition。比如topic包含6个partition，组由3个消费者组成，则每个消费者可分配2个partition
每个消费者组都有自己的offset，互不干扰

=============================kafka和rabbitmq、activemq、rocketmq的区别=============================

1.kafka主要支持发布订阅模式，其他三种则支持点对点和发布订阅模式
2.kafka吞吐量达百万，其他三者吞吐量较低
3.kafka使用简单，易于部署，但实现高级功能需要复杂配置。其他三者提供了更多功能，但也增加开发的复杂度
4.功能区别
                优先队列        延迟队列        死信队列        消费模式        事务消息
kafka           不支持         不支持            不           拉              支持
rocketmq        支持           支持             支持         推和拉           支持
rabbitmq        支持          插件支持           支持         推和拉           支持

=============================kafka为何快=============================

1.批量发送。用户是一条一条发送消息，但kafka将多个消息打包成一个批次一起发
2.异步发送，消息被放到本地的缓存中，就返回了，不必等待。消息数量达到阈值或时间达到阈值时，后台线程会发送
3.消息压缩
4.零拷贝
rocketmq为了支持各种高级特性（延迟队列、顺序消息、事务消息等），对可靠性要求很高，不允许批量发送
kafka诞生的背景是大数据、日志处理，可以丢一点

零拷贝
普通的读写流程如下
1.用户read发起系统调用，用户态切换到内核态，通过DMA技术将数据从磁盘拷贝到【内核缓冲区】            ---DMA做的
2.DMA完成后，发起一个中断，CPU将【内核缓冲区】中的内容拷贝到【用户缓冲区】                        ---CPU做的
线程切换回用户态，逻辑处理
3.将用户态中的内容拷贝到【socket缓冲区】（内核态） 用户态切换到内核态                            ---CPU做的
4.将【socket缓冲区】的数据拷贝到网卡                                                         ---DMA做的
网卡发送数据，线程切换回用户态
上面的过程中，数据经历了4次拷贝，4次上下文切换。所谓零拷贝，就是通过各种方法减少拷贝的次数，比如mmap，sendfile，dma，direct io等

DMA
正常来说，数据拷贝是需要CPU参与的：从外设（如磁盘）读取到cpu寄存器，再写入内存。DMA技术允许外设直接与内存交换数据，仅在开始和结束时通知CPU

mmap
数据从磁盘拷贝到【内核缓冲区】（DMA），【映射】到用户缓冲区（无需拷贝），【内核缓冲区】拷贝到【socket缓冲区】（CPU），【socket缓冲区】再拷贝到网卡（DMA）。一共两次DMA，一次CPU
允许程序像访问内存一样访问文件，无需read和write。
通过系统调用mmap()将磁盘映射到进程的虚拟地址，当程序读写映射的内存区域时，触发缺页异常，操作系统会将文件加载或写回
mmap在使用时必须指定映射的大小，因此不适合变长的文件。rocketmq就是采用的这种方式

sendFile
如果只是传输数据，不对数据做修改，则可以通过sendFile的方式，这也是kafka采用的方式
在linux 2.4之前，和mmap是一样的（2+1）
2.4之后：磁盘拷贝到【内核缓冲区】（DMA），【内核缓冲区】拷贝到网卡（DMA gather copy，需要网卡的硬件支持），只有2次DM拷贝，省去了CPU拷贝
上面的4次拷贝，有两次是浪费的：用户空间<-->内核空间。零拷贝就是把这两次拷贝绕过，应用程序可以把磁盘中的数据从内核直接发送到网卡，即磁盘->内核->网卡，零拷贝是针对用户空间而言的
对于生产者而言，sendfile直接拷贝数据发送给网卡，导致程序无法获取消息内容，无法做消息加工处理，这限制了kafka的功能。所以RocketMQ选择了更慢的mmap技术

=============================消费分区=============================

消费者消费的分区可以手动指定，也可以由kafka自动分配
手动指定的部分代码如下
KafkaConsumer<String, String> consumer = new KafkaConsumer<>(props);
TopicPartition partition = new TopicPartition("topic-name", 0); // 消费名为"topic-name"的主题的第0个分区
consumer.assign(Collections.singletonList(partition));
手动消费【不会】参与重平衡

=============================重平衡=============================

重平衡的目的是尽量保证每个消费者消费的分区数量均衡。以下几种情况会触发重平衡
1.消费者组新增或删除消费者（最常见，比如消费者实例重启）
2.partition数量发生变化
3.topic发生变化（有些消费者通过正则订阅topic，新增符合条件的topic时，消费者组会感受到，从而触发重平衡）
过程大致如下
1.暂停消费
2.根据分区的分配策略（比如range或round-robin）重新计算分配方案
3.通知消费者并要求他们重新加入消费者组
4.应用分配方案，重新分配partition
5.恢复消费
缺点：重平衡会导致短暂的服务不可用

=============================高水位=============================
高水位（High Watermark，简称 HW） 是一个关键概念，用于标识分区中已完成复制的消息边界，确保数据的可靠性和一致性。
高水位代表分区中所有副本（包括 leader 和 follower）都已成功同步的最高消息位置。
对于消费者而言，只能消费高水位以下的消息（即 offset 小于高水位的消息），这保证了消费者只能看到已完成复制的、不会丢失的消息。
Kafka 的日志清理机制（如删除旧日志段）只会清理高水位以下的过期数据，确保未完成同步的消息不会被过早删除。

=============================LEO=============================
LEO 是每个副本（Replica） 本地日志中最后一条消息的下一个位置（偏移量）。
例如：若一个副本的日志中包含偏移量为 0、1、2 的消息，则其 LEO 为 3，表示下一条写入的消息将使用偏移量 3。
LEO 是每个副本独立维护的变量，不同副本的 LEO 可能因同步进度不同而存在差异。
LEO 直观反映了某个副本当前的日志写入进度，数值越大表示该副本包含的消息越多。
分区的高水位（HW）由该分区所有 ISR（同步副本集） 中最小的 LEO 决定。即：
HW = min(所有 ISR 副本的 LEO)
Follower 副本通过对比自身 LEO 与 Leader 副本的 LEO，判断需要从 Leader 同步哪些消息（从自身 LEO 位置开始拉取）。

=============================controller=============================
作用：1.管理partition的leader选举
2.协调broker的上下线
3.管理分区的创建、删除、重分配

=============================消息可靠性=============================
producer
生产者可以配置acks参数来控制broker对消息的确认级别
acks=0：不等待broker确认，直接认为成功
acks=1：默认，表示等待分区的leader确认
acks=-1/all：等待leader及所有的同步副本（ISR）都确认
配置重试：retries=3和retry.backoff.ms=1000 重试3次，重试间隔1秒

consumer
取消offset自动提交：enable.auto.commit=false
消费成功后提交offset
