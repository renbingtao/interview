
========================表、栈和队列========================

表（list）比较简单，跳过

栈（stack）
栈是限制插入和删除只能在一个位置上进行的表（list），该位置是表的末端，叫做栈的顶（top）。对栈的基本操作有push（进栈）和pop（出栈）。栈有时又叫做LIFO（后进先出）表。栈一般的模型是，存在某个元素位于栈顶，而该元素是唯一的可见元素
栈的实现
由于栈是一个表，因此任何实现表的方法都能实现栈，包括ArrayList 和LinkedList，前者更加流行。栈很可能是计算机科学中在数组之后的最基本的数据机构
栈的应用
1.平衡符号
编译器检查程序的语法错误时，经常检查符号是否成对出现，比如[()]是合法的，([)]是非法的。
这个算法用到一个栈：创建一个空栈，读入全部字符，若字符为开放符号，比如"("，则push；若字符是封闭符号，栈为空则报错，否则pop，若pop出的符号不是对应的开放符号。在结尾，若栈为非空则报错
2.后缀表达式
计算4.99*1.06+5.99+6.99*1.06，可将操作书写如下：4.99 1.06 * 5.99 + 6.99 1.06 * +
这个记法叫做后缀（或逆波兰）记法。对于后缀表达式的计算，可用栈解决：遇到一个数就push，遇到计算符号就pop出两个，将计算结果push，最后栈中只有一个元素，即结果
中缀到后缀的转换
假设有中缀表达式（也叫做标准形式的表达式）：a+b*c+(d*e+f)*g，将其变成后缀表达式，结果为abc*+de*f+g*+ 过程复杂跳过
3.方法调用
调用新方法时，主调例程的所有局部变量都要存储，包括当前位置也要存储，以便新方法运行完后向哪里跳转。这个问题和平衡符号很类似，方法调用和方法返回类似于开括号和闭括号

队列（queue）
队列也是表，但使用队列时，插入在一端进行，删除在另一端进行
队列的基本操作包括：enqueue（入队），在表的末端（或队尾）插入一个元素；dequeue（出队），删除并返回表的开头（或队头）的元素
队列的应用
访计算机用户访问文件服务器（file server）中的文件是按照先到先得的原则访问，因此其数据结构是一个队列

========================树========================

树的遍历
private void listAll(int depth){
    printName(depth)
    if(isDirectory()){
        foreach(file c:directory){
            c.listAll(depth+1)
        }
    }
}
上述遍历策略称为【先序遍历】，即对节点的处理是在它的诸多儿子节点被处理之前进行的
另一种遍历方法时【后序遍历】，即先处理儿子节点，再处理本节点

二叉查找树
对于树中的每个节点X，它的左子树所有项的值小于X中的项，右子树中所有项的值大于X中的项。【中序遍历】：先处理左子树，然后当前节点，最后处理右子树

伸展树
本质上是二叉查找树，它的特点是把最近访问的节点移动到根节点，后续访问相同节点时能减少时间开销，所以很适合缓存

平衡二叉树
最矮的树和最高的树高度差最多为1，即平衡因子=左子树高度-右子树高度的绝对值<=1。不平衡时，再判断不平衡的子树是左节点还是右节点插入导致的不平衡
LL型(平衡因子=2且子树的平衡因子=1)右旋，RR同理左旋；LR型（平衡因子=2且子树的平衡因子=-1）左右旋，同理RL型右左旋
查询时间复杂度O（log n），n为节点总数
适用于插入删除少，查询多的场景

红黑树
由于平衡二叉树对高度差的要求很高，需要频繁旋转，插入性能差，因此定义了红黑树，减少旋转次数。最高的树的高度最多是最矮的树的高度的2倍
规则：是搜索树（左根右）。每个节点为红或者黑。根及叶子节点为黑，这里的叶子节点指的是最下面的节点下的null节点。连续两个节点不能为红。根到叶子节点（null）的黑色节点总数一致
规则总结为：左根右，根叶黑，不红红，黑路同
插入时，默认插入红色节点。当不满足规则时，进行判定：叔叔节点是红还是黑？如果是红色，则父叔爷三个节点变色（红变黑，黑变红），同时爷爷节点变为插入节点，重复上述操作；如果是黑色，进行LL、RR等旋转（参考平衡二叉树），然后对旋转点及中心点进行变色

B树
B树为M叉查找树，即节点最多有M个子节点，阶为M（二叉树的阶为2）
节点的扇出在M/2到M之间
所有叶子节点的高度一致；内部节点包含关键字、记录指针、指向下一节点的指针
所有节点的关键字都是从小到大排序

B+树
B树的升级版，内部节点不保存记录指针，使得扇出变大，树矮胖。适合内存有限

========================散列========================

散列表的实现常常叫做散列（hashing），是一种以常数平均时间执行插入、删除和查找的技术，但是不支持排序相关操作

散列函数
一个相对好的散列函数示例
public static int hash(String key,int tableSize){
    int hashVal=0;
    for(int i=0;i<key.length();i++){
        hashVal=37*hashVal+key.charAt(i);
    }
    hashVal%=tableSize;
    if(hashVal<0)
        hashVal+=tableSize;
    return hashVal;
}
计算时hashVal可能溢出，可能导致出现负数，因此末尾进行了负数处理
接下来讨论出现hash冲突时解决方法

分离链接法
即将冲突的元素都保存在一个表中，采用头插（不光是简单，而且新插入的元素最有可能不久被访问）

开放定址法
分离链接法的缺点是使用链表，分配地址需要时间，导致速度减慢。另一种方案是尝试另外一些单元，直到找出空的单元为止
h0(x),h1(x),h2(x),...相继被诗选，其中hi(x)=(hash(x)+f(i)) mod TableSize，且f(0)=0。f是冲突解决方法
由于所有数据都放在表内，因此这种方案所需要的表比分离链接法的表要大，一般来说负载因子要小于0.5。我们把这种表称为探测散列表

线性探测法
f是i的线性函数，典型为f(i)=i。举例：hash表size为10，hash(key)=key%10。插入一下键值对：89,18,49,58,69
89放在索引9
18放在索引8
插入49时产生冲突，它被放在写一个空闲地址，即索引0
插入58时和18冲突，试图放入索引0，又和49冲突，放入索引1
插入69和89、49、58冲突，放入索引2
有点：空间利用率高
缺点：即使表相对较空，占据的单元也会形成一些区块，这种结果称为一次聚集，导致查找和插入效率变低

平方探测法
平方探测法是消除线性探测中一次聚集问题的冲突解决办法，流行选择时f(i)=i2。仍然用上面的例子举例
89放在索引9
18放在索引8
49冲突，i=0，放在索引0
58和18冲突。i=0和49冲突。i=1时（58+1*1）mod 10=9，和89冲突。i=2时（58+2*2）mod 10=2，即放在索引2
69和89冲突。i=0和49冲突。i=1时（69+1*1）mod 10=0冲突。i=2时（69+2*2）mod 10=3，即放在索引3
优点：避免聚集现象，避免局部空间过度拥挤
缺点：负载因子很高时，探测序列会变长，性能变差；负载因子小于0.5时不保证一定能找到位置，需要扩容

双散列
流行公式是f(i)=i*hash2(x)。hash2函数选择得不好将会是灾难性的。hash2(x)=R-(x mod R)是一个良好的函数，其中R是小于tablesize的素数（质数）
优点：均匀分布，减少冲突的概率
缺点：计算成本高；复杂，对第二个散列函数的要求高

========================优先队列（堆）========================

我们给队列中的每个元素都分配一个数字来标记优先级，这样我们就可以在一个集合中访问优先级最高的元素并进行查找删除操作了
优先队列至少要包含两种操作：insert和deleteMin。后者的工作是找出、返回并删除优先队列中最小的元素

二叉堆
我们可以使用二叉堆来实现优先队列，且这种实现非常普遍。后续简称堆

堆的结构性质
一个完全二叉树。可以用数组来表示、存储：按照从上到下，从左到右的顺序保存在数组中，根节点放在下标1。对于数组中任意下标i的元素，其左儿子下标为2i，右儿子下标为2i+1，父亲下标为[i/2]（向下取整）
         A
   B          C
D     E    F    G
上述二叉树用数组保存为[空,A,B,C,D,E,F,G,空,空]

堆序性质
我们需要找到最小元，则最小元应该在根上。若考虑任意子树也是一个堆，则任意节点应该小于它的所有后裔。基于此，我们得到堆序性质：在一个堆中，对于每一个节点X，X的父亲的关键字小于（或等于）X中的关键字，根节点除外。即从根出发，到叶子节点，是递增的
根据堆序性质，最小元总可以在根找到，因此我们以常数时间得到附加操作findMin
这种称为小根堆，最小堆。若根节点为最大，依次递减，则为大根堆

insert操作
为将一个元素X插入到堆中，需要在下一个可用位置创建一个空穴，否则堆将不是完全树。如果X放入空穴后不破坏堆的序，则插入完成。否则把空穴的父节点的元素移入空穴，这样空穴就向着根的方向前进一步，依次类推，直到X能被放入空穴。时间复杂度为O(logN)。这种策略叫做【上虑】。方便记忆：最下面的元素位置不对，要找到它正确的位置，因此从下到上遍历，所以是上滤

deleteMin操作
找出最小元是容易的，难的是删除它。删除一个最小元时，要在根节点建立一个空穴。由于堆少了一个元素，因此要移动最后一个元素X，若X可以被放入空穴，则deleteMin操作完成，不过一般不可能，因此将空穴的两个儿子中的较小者移入空穴，则此时空穴向下推了一层。重复上述过程直到X可以被放入空穴。即从根开始，根据最小儿子的路径，将X插入到正确的位置。时间复杂度为O(logN)。这种策略叫做【下虑】。方便记忆：最上面的元素位置不对，因此从上到下遍历，找到它正确的位置，因此叫下滤

其他的堆操作
最小堆在求最大元方面没有帮助。一个堆蕴含的排序信息很少。关于最大元，唯一知道的信息是该元素在树叶上，但是一个堆中一半的元素都在树叶上，因此该信息价值不大。如果想要知道元素在什么地方，则除了堆之外，还需要使用其他数据结构，比如散列表。我们假设通过其他方法得知每一个元素的位置，那么下列的操作开销会变小：

decreaseKey降低关键字的值
decreaseKey(p,a)操作降低位置（下标）p处的项的值，降幅为a，由于可能破坏堆序性质，必须通过上滤对堆进行调整

increaseKey降低关键字的值
同理，通过下滤调整

delete删除
delete(p)删除堆中位置p上的节点，首先执行decreaseKey(p,+∞)，然后deleteMin()

buildHeap构建堆
自顶向下
适用于逐个插入元素。对每个元素，执行插入堆，上滤。时间复杂度时O(NlogN)。由于树的顶部总是排好序的，因此叫自顶向下

自底向上
适用于已知所有元素后批量构建堆。假设堆有N个元素，直接构建一个堆（此时不满足堆序性质），从最后一个非叶子节点开始（位置为N/2或向下取整），向前遍历所有节点，对节点执行下滤。时间复杂度为O(N)。由于树的底部总是排好序的，因此叫自底向上

优先队列的应用
选择问题，即有N个元素，找出第k大的
算法一：将N个元素读入数组，调用buildHeap（耗时N），执行k次deleteMin（耗时klogN），即可得到第k小的元素，时间复杂度为O(N+klogN)，k=N/2时，为O(NlogN)。只需要把小根堆改成大根堆即可得到第k大的
算法二：将前k个元素读入数组并调用buildHeap构建小根堆（耗时k），对剩下的N-k个元素检查（耗时1），大于堆的最小值则删除并插入新值（耗时(N-k)*logk），总耗时O(Nlogk)j，k=N/2时为O(NlogN)

========================图论算法========================

定义
【图】由【顶点】和【边】组成。一个边（也叫弧）就是一幅【点对】（v，w）。如果边是有序的，则图是【有向图】，否则是【无向图】。有时边还有权重（也叫【权】或【值】）
圈是指一种特殊的闭合路径，核心特征是起点与终点完全重合，且路径中所有边和除端点外的顶点均不重复。比如A→B→C→A是圈，A→B→A→C→A则不是（是回路），A→A也不是（是环）。有向无圈图也称为DAG
入度：A→B,C→B 则顶点B的入度为2。出度同理
若无向图中任一顶点都能到达另一顶点，则称为【连通图】，有向图则称为【强连通图】。若有向图不是强连通的，但【基础图】即去掉方向的图，是连通的，则称为【弱连通】
邻接矩阵：对于每条边（u，v），连通则A[u][v]=true，否则为false；如果有权则A[u][v]表示权。邻接矩阵的问题是空间复杂度O（n平方），如果边不是很多（稀疏的图），则浪费空间，因此适合稠密的图，即点少边多
邻接表：使用数组+链表，数组保存了全部的点，链表里保存了数组元素邻接的顶点。邻接表是表示图的标准方法

拓扑排序
对有向无圈图的顶点的一种排序，且先完成依赖，再做后面的事（即若存在边u->v，则排序中u一定在v前面）。如果图中有圈，那么拓扑排序是不可能的。拓扑序不唯一
拓扑排序的本质是将 DAG 的 “依赖关系” 转化为线性顺序，核心价值是解决 “有前置条件的任务调度” 问题

最短路径算法
即从A点到其他点的最短路径
解决单源最短路径问题的一般方法叫Dijkstra算法，是贪心算法，每次选择距离A最近的点。该算法每一次遍历都得到距离A最近的点，而不是针对某个点计算全部路径取最小值
思路：遍历A，找到距离最短的点B，标记为已解决（其他节点为CD）。接下来循环：遍历B（得到CEF），C=min(ABC,AC)，A到CDEF中最小的（比如是E）标记为已解决。再遍历E

网络流问题
顶点A到顶点B，从顶点A输入水流x，在顶点B全部流出，每个边有的权重为能够接收的最大水流（容量）。最大流问题是确定从A到B能够通过的最大流量
一种简单的最大流算法
找到任意A->B的路径，计算路径的最小权重（类比成木桶的最短板），该路径所有边减去权重，减为0时删除该边，差值作为容量。重复上述过程，直到不存在A->B的路径为止，此时的权重为空闲量。流量=容量-空闲量，再计算A的流出的流量总和，即为最大流
简单最大流算法的问题是，不能保证结果一定是最大的，结果和路径的先后顺序有很大关系
某个路径集合导致流量无法增大，则称为阻塞流。最大流也是一种阻塞流
Ford-Fulkerson算法可以保证一定取得最大流。在删除权重时，添加一个反方向的流，可以用来搜索A->B的路径，除此之外一样
Edmonds-Karp算法是对Ford-Fulkerson算法的一种特例，唯一改动是搜索A->B的路径时总是搜索最短路径（按照无权重图处理，即最小边数）

最小生成树
在无向图中找出一颗最小生成树（包含全部顶点），每个边都有权重，这里的最小指的是边的权重的和最小。一个树有n个点，n-1个边。最小生成树不唯一，但权重和是唯一的
prim算法
加点法，一开始只有一个顶点，在每一步都把一个节点当成根节点，将邻接的权重最小的节点加入树。点多时，要遍历的点就多，所以效率低，因此更适合稠密图
kruskal算法
加边法，一开始所有点都是孤立的，每次遍历所有的边（当前边和现有的树不能在一个连通分量里。举例：A-B-C-D在一个树里，则BD这个边和树是在一个连通分量里，因此不考虑），找到权重最小的边，连接起来。边多时效率低，因此更适合稀疏图

图的基础遍历方式
图的遍历核心是从指定起点出发，按规则访问图中所有顶点且不重复
主流方式有两种：深度优先搜索 和 广度优先搜索

========================排序========================

堆排序
将包含N个元素的数组构建成二叉堆，耗时O(NlogN)，然后执行N次deleteMin，即最小的元素依次离开堆，将它们记录到新建的数组中，即可得到N个元素的排序
上面算法的问题是使用了附加的数组，内存消耗翻倍。解决方案：每次deleteMin后，堆的大小-1，可以把最后删除的元素放入堆中最后的单元。如果是小根堆，通过这种策略，在最后一次deleteMin后，数组中的元素是递减的。改成大根堆即可实现递增
举例：堆有6个元素，第一次deleteMin删除a1，把a1放在位置6；第二次deleteMin删除a2，把a2放入位置5
举例：输入的序列为[31,41,59,26,53,58,97]，得到堆如下
            97
    53              59
26      41      58      31
数组为[null,97,53,59,26,41,58,31,null,null,null]

进行第一次deleteMin后，结果如下
            59
    53              58
26      41      31      (97)
其中97已删除，并放入最后一个单元
数组为[null,59,53,58,26,41,31,97,null,null,null]

归并排序
这个算法的基本操作是合并两个已排序的表。基本的合并算法是取两个输入数组A和B，一个输出数组C，以及三个计数器a，b，c，分别对应ABC的开始位置，将a、b中的较小者（比如是a）复制到c，并将a的计数器+1，当AB任意一个表使用完，将另一个表的剩余部分复制到C中
该算法是典型的分治策略，它将问题【分】成一些小的问题然后递归求解，而【治】的阶段则将分阶段得到的各答案修补到一起。时间复杂度是O(NlogN)

外部排序
之前的算法都需要把输入数据装入内存，处理大量数据（内存）排序可以使用外部排序

简单算法
假设有4盘磁盘，T1T2是输入磁盘，T3T4是输出磁盘。假设开始时数据全部在T1上，一共有N条记录，内存可以容纳M个记录。从T1里读取M个记录到内存，进行排序，然后交替写入T3和T4，做完这些后，倒回所有的磁盘（移动磁头）。每组排序过的记录叫做一个【顺串】
如果M=3，则顺串构造后，磁盘如下
T1
T2
T3  11 81 94        17 28 99        15
T4  12 35 96        41 58 75
然后我们把T3和T4的第一个顺串取出并合并，把结果写入T1，结果为长度为二倍长（6）的顺串。合并两个顺串是简单操作，几乎不需要内存。然后再从T3和T4中取出下一个顺串，合并，将结果写入T2。重复上述过程，直到T3或T4为空，若剩下一个顺串，则直接拷贝到磁盘上。经过这步，得到长度为四倍长（12）的若干顺串。重复上述过程，直到得到长度为N的顺串

多路合并
若我们多余的磁盘，可以减少排序的次数，将2路合并扩充为k路合并。和上面的算法类似，唯一区别是，k个顺串合并时，需要从k个元素中找到最小的元素。我们可以使用优先队列找出这些元素中的最小值，通过deleteMin即可得到。找出并删除后，读取下一个元素，并放入小根堆中

替换选择
对于顺串的构造，可以进行优化：将第一个记录写到输出磁盘上，则它的内存可以被其他记录使用，若输入的下一个元素比刚刚的输出大，则它可以被放入顺串中，这种方法称为【替换选择】。过程如下
M个记录被读入内存并放入优先队列中，执行deleteMin并把最小值a写入输出磁盘，然后读取下一个记录b，若b>a，则b可以添加到优先队列；否则把b存入优先队列的死区（优先队列数组中不会被读取的那部分）。重复上面的步骤，直到优先队列大小为0，此时顺串构建完成。再使用死区的所有元素建立一个新的顺串
如果输入数据是随机分布的，则效果不一定比标准算法好；然而实际上输入数据常常是已排序或几乎已排序，则替换选择会产生少数且很长的顺串，从而提升效率

贪心算法与动态规划的区别
贪心算法追求局部最优解，划分的每个子问题都最优，但不能保证全局最优
动态规划：将问题分解为重复的子问题，每次都寻找左右子问题解中最优的解，一步步得到全局最优解。重复的子问题可以记录下来，避免重复计算
比如钱币分为1、3、4元，要6元，贪心先拿4，再拿两个1；而动态规划拿两个3

分治法
与动态规划类似，将大问题分解为小问题，但这些小问题是独立的
