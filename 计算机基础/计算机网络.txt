
========================基础概念========================
将网络互相连接起来需要使用一些中间设备
物理层使用的叫做转发器
数据链路层使用的叫做网桥或桥接器
网络层使用的叫做路由器
网络层及以上使用的叫做网关

使用转发器或网桥，仅仅是把网络扩大了，但仍是一个网络，所以不能称为网络互连
我们讨论网络互联时，都是指用路由器进行网络互联和路由选择。由于历史原因，很多文献也把路由器成为网关
互联的计算机网络都是相同的IP协议，连接成逻辑互联网络（即互联的各种物理网络的异构性是客观存在的，但使用IP协议可以让它们看起来是一个统一的网络）

========================数据链路层========================
数据链路层使用的信道有两种类型：点对点信道、广播信道
以下面为例，H代表主机，R代表路由器
H1->R1->R2->R3->H2
主机有完整的5层协议栈，路由器只有3层（物理、数据链路、网络）。数据进入路由器后要从物理层上升到网络层，在转发表中找到下一跳的地址后，再下到物理层转发出去。因此，数据从主机H1传送到H2需要在路径中的各节点的协议栈向上和向下流动多次

链路：一个节点到相邻节点的一段物理线路（有线或无线），中间没有其他的交换节点
数据链路：在一条线路传送数据时，除了物理线路，还需要通信协议来控制数据的传输。把这些实现协议的软硬件加到链路上，就构成了数据链路。现在最常用的方法是使用网络适配器来实现协议

帧
点对点信道的数据链路层的协议数据单元，网络层的单元是IP数据报
以结点A发送数据到结点B为例，通信的主要步骤如下
1.A的数据链路层收到网络层的IP数据报，添加首部和尾部组装成帧
2.A把封装好的帧发送给B
3.若B的数据链路层收到的帧无差错，则从帧中提取出IP数据报上交给网络层，否则丢弃这个帧

数据链路层协议的三个基本问题
封装成帧、透明传输、差错检测

封装成帧
即在一段数据的前后添加首部和尾部。一个帧的帧长等于帧的【数据部分】长度+帧首部和尾部的长度。首尾部的一个重要作用是进行帧定界（确认帧的界限）。每种数据链路层协议都规定了所能传送的帧的数据部分的上限-最大传送单元MTU
当数据是由可打印的ASCII码（一共128个码，95个可打印，33个不可打印）组成的文本文件时，帧定界可以用特殊的帧定界符。控制字符为SOH（start of header，表示首部的开始，二进制为00000001）和EOT（end of transmission，表示帧的结束，二进制为00000100）
当发送端发送帧时出现故障，又恢复，重新发送。由于只有SOH而没有EOT，接收端知道前一个数据是不完整的，舍弃；后面收到的帧有SOH和EOT，完整，收下

透明传输
数据部分不能包含SOH和EOT。通过键盘输入字符时不会输入控制字符，这种就叫透明传输
若数据部分是非ACSII码的文本文件（比如二进制代码的程序或图像），可能包含SOH和EOT，导致数据链路层找到错误的帧边界
所谓透明，表示无论什么样的数据，都能按照原样进行传输，数据看不见数据链路层有什么妨碍传输的东西，或者说数据链路层对数据是透明的
为了让数据部分的SOH和EOT不被错误解释，数据链路层在SOH和EOT前插入转义字符ESC（二进制00011011），接收端先删除转义符，再发给网络层。若转义字符也在数据中，则在转义字符前也插入转义字符

差错检测
比特在传输过程中，1可能变成0，0也可能变成1，这种叫做比特差错。目前广泛使用循环冗余检验CRC的检错技术
举例，要传送的数据M为101001（长度k=6），双方约定一个数P，比如1101（长度为3+1，n=3），则用101001000（M后面添加n个0）除以P，得到余数001，发送101001001（M+余数，共k+n）。接收端把收到的数据除以P，得到余数R，若R=0则无差错；否则有差错，舍弃（数据有差错且R=0的情况概率极小）。这种为了检错而添加的冗余码称为FCS，CRC是检测方法，而FCS是在后面添加的冗余码，两者不是同一概念
CRC仅能做到帧的无差错接收，但无法做到可靠传输（数据链路层的发送端发什么，接收端就收什么）。比如帧丢失，帧重复，帧失序，属于传输差错，而非比特差错

点对点协议
也叫PPP，point-to-point protocal。PPP帧的首部包含4个字段，尾部包含2个字段
标志字段        F       A       C       协议      信息部分        FCS    F
字符            7E      FF      03                                      7E
字节长度        1       1       1       2         不超过1500      2      1
第一和最后的字段为0x7E，0x表示后面的字符为16进制，表示帧的开始或结束。FF和03是当初预留的字段的值，但至今也没有其他定义，因此实际上是无效信息
协议字段为0x0021时，表示IP数据报；0xC021表示链路控制协议LCP的数据；0x8021表示网络层的控制数据
当信息部分出现0x7E时，进行转义

MAC
48位的全球地址，局域网上的每一台计算机中固化在适配器的ROM中的地址。若主机或路由器有多个适配器，则有多个地址

========================网络层========================
与IP协议配套使用的有三个协议：ARP，ICMP，IGMP，关系如下
ICMP,IGMP
IP
ARP
ARP在最下是因为IP需要使用这个协议，ICMP\IGMP在上是因为它们要使用IP协议

源主机H1要把IP数据报发送给H2
H1->R1->R2->R3->R4->R5->H2
H1查找自己的路由表，看目的主机是否在本网络上，若是，则直接交付；不是则转发给路由器（R1），R1查找自己的路由表后，转发给R2进行间接交付，一直转发到R5，由于R5和H2是连接在同一个网络上，因此直接交付给目的主机

IP地址及表示方法
IP地址的编址方法经过了三个历史阶段：分类的IP地址；子网的划分；构成超网
所谓分类，即将IP地址分为若干固定类，这里的A,B,C类地址都由两个固定长度的字段组成，第一个字段是网络号，在整个互联网范围内必须是唯一的；第二个字段是主机号，标识该主机或路由器，一个主机号在一个网络号范围内必须唯一，因此IP在整个互联网也是唯一的

A类地址
0|网络号|主机号
8位    |24位

B类地址
10|网络号|主机号
16位    |16位

C类地址
110|网络号|主机号
24位      |8位

D类地址
1110|多播地址

举例：C类网络第一个可指派的网络号为192.0.1，最后一个可指派的网络号为223.255.255
ABC类的区分已成历史。当初分类是因为各网络差异很大，有些网络主机多，有些主机少，对IP地址进行划分可以满足不同用户的要求

IP分为网络号和主机号的好处
1.IP地址管理机构在分配IP地址时只分配网络号（第一级），剩下的主机号（第二级）由得到网络号的单位自行分配，方便了IP地址的管理
2.路由器仅根据目的主机的网络号进行转发，减少了路由表占用的空间，减少了查询时间

IP地址实际是标识一台主机（或路由）和一条链路的接口。若一台主机同时连接到两个网络上时，则必须拥有两个IP地址，网络号必须是不同的，这种称为多归属主机。由于路由器至少连接到两个网络，故路由器至少有两个不同ip

一个网络指具有相同网络号net-id主机的集合，因此用转发器或网桥连接起来的若干局域网仍是一个网络，因为这些局域网具有同样的网络号。不同网络号的局域网必须用路由器互联

物理地址是数据链路层和物理层使用的地址，IP地址是网络层和以上使用的地址，是逻辑地址，用软件实现
数据从主机H1经过R1、R2路由器到达主机H2，网络层看到的IP的源地址和目的地址始终不变。路由器进行路由选择时，只根据目的地址的IP地址的网络号进行选择
在链路层，只能看见MAC帧。MAC帧在不同网络上传送时，MAC帧首部中的源地址和目的地址会发生变化，IP层是看不到这种变化的

HA代表硬件地址
H1 （HA1 局域网 HA3） 路由器R1 （HA4 局域网 HA5） 路由器R2 （HA6 局域网 HA2） H2
        MAC帧首部地址
H1->R1  HA1 -> HA3
R1->R2  HA4 -> HA5
R2->H2  HA6 -> HA2

ARP协议
通过主机或路由器的IP地址，找到对应的硬件地址
每台主机都有一个ARP高速缓存，里面有本局域网上的各主机和路由器的IP->硬件地址的映射表
A主机向B主机发送IP数据，A先在ARP缓存查找B的IP地址，找不到时，ARP进程在本局域网上广播发送ARP请求分组，内容大概为：我的ip地址为xx，硬件地址为xx，我想知道ip为xx的主机的硬件地址。本局域网上所有主机的ARP进程都会收到此请求，由于B主机的主机与查询的IP地址一致，故发送ARP响应分组，内容大概为：我的ip是xx，硬件地址为xx。其他主机会忽视这个请求。A主机会缓存B的ip、mac映射关系，B主机也会缓存A主机的映射。缓存有生存时间（比如10-20分钟）
ARP是解决【同一个局域网】上的IP地址与硬件地址的映射问题。若不在同一个局域网，则由路由器转发，源主机把路由器的ip地址解析为硬件地址，以便把数据送到路由器；路由器从转发表找出下一跳路由器，使用ARP解析出硬件地址

总结出使用ARP的四种典型情况
发送方类型   源和目的是否在同一网络      行为
主机          是                       发送ARP请求分组，找到目的主机的硬件地址
主机          否                       发送ARP请求分组，找到同网络内的路由器的硬件地址，剩下的工作由路由器完成（下面2中情况）
路由器        是                       发送ARP请求分组，找到目的主机的硬件地址
路由器        否                       发送ARP请求分组，找到同网络内的另一个路由器R2的硬件地址，剩下的工作由R2完成

为什么有了MAC地址还需要IP地址
为了使各种异构网络能够通信，需要进行复杂的硬件地址转换工作，由用户或用户主机来完成几乎不可能。但使用IP地址可以把复杂的ARP过程隐藏，简单方便

IP数据报的格式
IP数据报=首部（固定20字节+可变部分）+数据。首部的字段如下：
版本，4位
首部长度，4位（长度可变，因为首部部分字段是可选的）
区分服务，8位，一般情况下不使用
总长度，16位，指首部+数据的总长度，单位字节，故数据报的最大长度为2的16次方-1=65535字节。（实际很少这么长）
标识，16位，每产生一个数据报，该标识位就+1。数据报分片（超过MTU）时，每个片段的标识都相同
标志，3位，目前只有两位有意义。中间位为DF（dont fragment，不能分片），为0时才允许分片；最低位为MF（more fragment），为1表示后面还有分片，为0表示这是分片中的最后一个
片偏移，13位，分片后，每个分片相对分片前的位置，可理解为偏移量
生存时间，8位，由发送方设置，防止无法交付的数据报无限循环（R1-R2-R3-R1）。开始单位为秒，若经过路由器的耗时时间小于1s，则TTL-1,；随着技术进步，路由器处理速度远小于1s，故把TTL的功能改为跳数限制（名称保持不变），路由器在转发数据报前把TTL-1，若减少到了0，则丢弃。若TTL=1，表示数据报只能在本局域网中传送
协议，8位，指出该数据报携带的数据是何种协议，这样上层就知道该如何处理。常用协议：ICMP,IGMP,TCP,UDP,IPv6
首部校验和，16位，只校验数据报的首部，不包括数据部分。校验结果出错则数据报舍弃

由于链路层都规定了MTU（最大传送单元），因此IP数据报的总长（首部+数据）不能超过下层规定的MTU。比如以太网的MTU为1500字节。若超过，则需要分片处理
理论上，IP数据报越大，则首部占比越小，传输效率越高。但数据报越短，则路由转发的速度越快，因此IP协议规定，主机和路由器必须接收不超过576字节（上层交下来的数据512，首部60,富余4）的数据报

转发分组的流程
举例：网络1-R1-网络2-R2-网络3-R3-网络4。上述4个网络由3个路由器连接。若每个网络内有1w台主机，若路由表需要记录每台主机应怎样转发，则路由表有4w行记录。若路由表记录到某个网络该如何转发，则记录只有4条。以R2为例，若目的主机在网络2或者网络3，则R2可直接交付（通过ARP）；若目的主机在网络1，则下一跳路由器应为R1，由于R1和R2都连接在网络网络2，所以这种事情很容易做。互联网上进行转发分组时，可简化为由一个路由器转发到另一个路由器
在路由表中，每一条路由最重要的两个信息为：目的网络地址，下一跳地址。根据目的网络地址来确定下一跳路由器，可推测出：1.IP数据报一定可以找到目的主机所在目的网络上的路由器2.只有到达最后一个路由器时，才会像目的主机直接交付

所有的分组转发都是基于目的主机所在网络，但很多时候都允许特定目的主机指明一个路由，这种路由叫特定主机路由

当一个网络只有很少的对外连接时，采用默认路由可以减少路由表所占用的空间和搜索路由表所用的时间。举例：N2-R2-N1-R1-互联网，N为网络，则N1的路由表如下
目的网络    下一跳
N1          0.0.0.0
N2          R2
0.0.0.0     R1
其中0.0.0.0即为默认路由

有一个问题，IP数据报只记录了源IP和目标IP，没有下一跳路由器的IP，那如何找到下一跳路由器？
路由器收到IP数据报后，从路由表中得到下一跳路由器的IP地址后，不是把地址填入IP数据报，而是交给数据链路层的网络接口软件，接口软件把IP下一跳路由器的IP转为MAC地址（必须使用ARP），然后放入链路层的MAC帧的首部，根据MAC地址找到下一跳路由器。即不断重复以下过程：查找路由表->ARP得到硬件地址->写入MAC首部

综上，分组转发算法如下：
1.从数据报的首部提取出目的主机的IP地址D，得出目的网络地址为N
2.若路由器与N直连，则直接交付，否则执行3
3.若路由表中有目的地址为D的特定主机路由，则把数据传送给对应的下一跳路由器，否则执行4
4.若路由表中有到达网络N的路由，则把数据传送给对应的下一跳路由器，否则执行5
5.若路由表有默认路由，则交给默认路由，否则执行6
6.报错

划分子网
原先两级IP地址（网络号+主机号）有很多问题：为每一个物理网络分配一个网络号会使得路由表变得很大；新开通的网络必须申请IP地址才能连接到互联网，无法应对紧急情况，不灵活。为了解决上述问题，由增加了【子网号字段】，二级IP地址变成了三级IP地址，这种做法叫划分子网。思路如下：
1.一个拥有许多物理网络的单位，可将所属的物理网络划分为若干个子网。划分子网是单位内部的事，外部网络看不见该网络由多少子网组成，因此对外仍是一个网络
2.划分子网的方法是从主机号借用若干位作为子网号（主机号也相应减少同样的位数）。三级IP地址如下：网络号，子网号，主机号
3.其他网络发送给本单位某主机的IP数据报，仍然根据目的网络号找到路由器，但路由器收到IP数据报后，再按照目的网络号和子网号找到目的子网，把IP数据报交付目的主机
举例：某单位拥有B类IP地址，网络号为145.13，即凡是目的地址为145.13.x.x的数据报都会被送到这个网络的路由器R。现把该网络划分为3个子网，假设子网号占用8位，则主机号只剩8位。三个子网分别为：145.13.3.0，145.13.7.0，145.13.12.0。划分网络后，对外仍是一个网络，地址仍为145.13.0.0，但路由器R收到外部数据后，再根据目的地址转发到对应的子网

子网掩码
从IP数据报的首部无法知道目的主机连接的网络是否进行了子网划分，因此使用子网掩码（subnet mask）获取子网信息
二级IP地址                  145.13.3.10
二级IP地址的子网掩码          255.255.0.0
三级IP地址                  145.13.3.10
三级IP地址的子网掩码          255.255.255.0
子网的网络地址               145.13.3.0
现在子网号为3的网络的网络地址为145.13.3.0。路由器R为了方便从目的IP地址中提取子网的网络地址，使用三级IP地址的子网掩码
使用子网掩码的好处：不管网络有没有划分子网，只要把子网掩码和IP地址进行与运算，即可得到网络地址
现在互联网标准规定：所有网络都必须使用子网掩码，同时路由表中也必须有子网掩码这一栏，若一个网络不划分子网，那么该网络的子网掩码就使用默认子网掩码。A类地址的默认子网掩码为255.0.0.0，以此类推
路由器在和相邻路由器交换路由信息时，必须把自己所在网络（或子网）的子网掩码告诉相邻路由器，路由表也要维护子网掩码

使用子网时分组的转发
划分子网后，路由表必须包含：目的网络地址、子网掩码、下一跳地址，此时路由器转发分组的算法如下
1.从数据报的首部提取目的IP地址D
2.判断能否直接交付。对路由器直连的网络逐一检查：用各网络的子网掩码和D进行与运算，若结果==该网络的网络地址，则直接交付，否则执行3
3.若路由表中有目的地址为D的特定主机路由，则把数据传送给指明的下一跳路由器，否则执行4
4.对路由表中的每一行（目的网络地址，子网掩码，下一跳地址），用子网掩码&D，若结果==该行的目的网络地址，则把数据传送给该行的下一跳路由器，否则执行5
5.若路由表有默认路由，则交给默认路由，否则执行6
6.报错

无分类编址（CIDR，读作sider）
互联网面临这些问题：B类地址很快会分配完毕；互联网主干上的路由表的条数急剧增长；IPv4的控件终将耗尽。为了解决这些问题，研究了无分类编址，其特点如下
1.消除了ABC类地址及子网划分。把IP地址分为网络前缀和主机号，并采用斜线记法，即IP后面加上/前缀位数，比如128.14.35.7/20
2.把网络前缀相同的连续的IP地址组成一个CIDR地址块，只要知道CIDR地址块中的任何一个地址，就可以知道该地址块的起始地址（最小地址）和最大地址，及地址块中的地址数。把块当成集合更容易理解
举例：已知某CIDR地址块中的一个地址为128.14.35.7/20，则地址块的最小地址为128.14.32.0，最大地址为128.14.47.255。主机号全0或全1的特殊地址一般不用。该地址块共有2的12次方个地址（主机号一共12位）
用最小地址+网络前缀位数指明这个地址块。比如上面的地址块可记为128.14.32.0/20。在不需要指出地址块的起始地址时，也可把这样的地址块简称为【/20 地址块】

使用32位的地址掩码，虽然CIDR不使用子网，但由于部分网络还在使用子网划分和子网掩码，故CIDR的地址掩码也可称为子网掩码。有连续的1和连续的0组成，1的个数为网络前缀的长度。比如/20地址块的地址掩码为20个1+12个0
举例：地址192.199.170.82/27不仅表示IP地址为192.199.170.82，还表示网络前缀有27位，因此这个地址块包含32（2的5次方）个IP地址

CIDR不使用子网指不需要在32的ip地址中指定若干位为子网号。但是分配到了CIDR地址块的单位还是可以划分出子网，但这些子网的网络前缀比整个单位的网络前缀要长
举例：单位的网络前缀有20位，划分为8个子网（需要3位），则子网的网络前缀就变为23位。子网仍是由网络号+主机号组成（即没有子网号）

局域网网段地址：局域网通常会被分配一个特定的网段地址，比如192.168.1.0/24。其中192.168.1.0是网段地址，/24表示子网掩码为 255.255.255.0，网段地址可以作为局域网在网络中的一种"标识范围"
网关地址：局域网要与其他网络（如互联网）进行通信，需要通过网关设备（通常是路由器）。网关设备有一个连接到局域网的接口，这个接口会配置一个IP地址，作为局域网内设备访问外部网络的出口地址，也可以看作是局域网与外部网络通信的一个"代表"地址，局域网内的设备在访问外部网络时，数据包会先发送到这个网关地址，再由网关转发到外部网络

路由聚合
由于一个CIDR地址块有很多地址，因此路由表中就利用CIDR地址块来查找目的网络，这种地址的聚合称为路由聚合，使得路由表中的一行数据可以表示原来传统分类地址的多个路由，路由聚合也称为构成超网
举例：有4个子网：192.168.0.0/24，192.168.1.0/24，192.168.2.0/24，192.168.3.0/24，他们的前22位是相同的，可以把它们聚合成一个超网192.168.0.0/22，因此路由表中只需要一条记录，而非4条

最长前缀匹配
IP地址由网络前缀和主机号组成，因此路由表的字段也应改为网络前缀和下一跳地址，这会导致路由表可能会得到不止一个结果，这时选择网络前缀最长的路由。前缀越长，地址块越小，路由就越精准
举例：某路由表包含俩条记录：206.0.68.0/22和206.0.71.128/25（只展示前缀）若目的主机的地址为206.0.71.130，则把该ip和两条记录的掩码进行与运算，发现和网络前缀都一致，那么选择前缀长度为25的记录转发

通过这种方式，如果一开始就把整个世界划分为四大地区，每个地区分配一个CIDE地址块，就可大大减少路由表的记录数。但CIDR是后面推出的
欧洲194/7；北美198/7；中美和南美200/7；亚洲和太平洋202/7；

网际控制报文协议ICMP
ICMP允许主机或路由器报告差错情况，提供异常有关的报告，是互联网的标准协议，但不是高层协议，而是IP层的协议，ICMP报文是封装在IP数据报中，作为其中的数据部分
ICMP一个重要应用就是ping，是应用层直接使用网络层ICMP的一个例子，没有走传输层的TCP或UDP

专用地址
有些机构内部的计算机之间需要通信，但不需要都和互联网通信，这种内部使用的计算机可以由机构自行分配IP地址，但IP也不能完全任意分配，若分配的IP和互联网中的某IP一致，且该计算机能访问互联网，会出现地址二义性的问题。
因此，规定了一些专用地址，只能用于机构内部的通信，而不能用于和互联网上的主机通信；同时互联网中的所有路由器，对于目的地址是专用地址的数据报一律不转发。这些专用地址块包括：
10.0.0.0        -   10.255.255.255  又称24位块
172.16.0.0      -   172.31.255.255  又称20位块
192.168.0.0     -   192.168.255.255 又称16位块
采用这种专用IP地址的网络称为本地互联网或者专网

VPN
有些大机构的部门分散在世界各地，这些部门间要通信，可以利用公用的互联网作为机构各专网间的通信载体，这种专网又称为VPN

网络地址转换NAT
专网的某主机已经分配了专用地址，又想和互联网上的主机通信，可以使用NAT，需要在路由器上安装NAT软件，同时要求路由器至少有一个外网ip
专网的主机访问互联网上的主机时，路由器把专用地址转为路由器的互联网IP地址，再转发；互联网主机应答时，目的IP地址也是路由器的IP地址，然后通过NAT地址转换表，把目的IP地址转为专用地址。若路由器有n个公网ip，则专网最多有n台主机可以接入公网，即并发最多n。为了更高效地利用公网ip，NAT转换表把运输层的端口号也使用上，这种叫做NAPT，但很多文献并没有对这两者进行区分，而是都使用NAT
专网ip+端口 <--> 路由器公网ip+端口 <--> 目的地址+端口
普通路由器在转发时，源IP及目标IP都不变，但NAT路由器一定会改变源或目标IP；另外普通路由器工作在网络层，NAT路由器需要查看并转换端口号，这本是传输层的事情，没有遵守层次关系，遭人批评

========================运输层========================
网络层和运输层的区别
网络层为主机间提供逻辑通信；运输层为应用进程间提供端到端的逻辑通信
运输层对收到的报文进行差错检测；网络层只检查首部，不检查数据

运输层向高层用户屏蔽了下面网络核心的细节，使应用进程看起来好像两个运输层的实体间有一个逻辑通信通道

传输层的端口号分为下列
服务器端使用的端口号，分为熟知端口号（或系统端口号，0-1023）和登记端口号（1024-49151）
应用程序        FTP     TELNET      DNS
熟知端口号      21      23          53

客户端使用的端口号，数值为49152-65535，这类端口号仅在客户进程运行时动态选择，所以又叫短暂端口号

UDP
在IP的数据报服务的基础上增加了很少功能。UDP主要特点如下
1.UDP在传送数据前不需要建立连接，收到UDP请求后不需要回复确认
2.尽最大努力交付，不保证可靠交付
3.面向报文。发送方的UDP对应用程序交下来的报文，添加首部后就交付给IP层。应用层的报文，不合并，也不拆分，有多长都直接发送。同理，接收方的UDP，对IP层交上的UDP用户数据报，去除首部后原封不动地交付给应用。应用需要控制报文的大小，若太大，则IP层会进行分片；太小则影响效率
4.没有拥塞控制，网络出现拥塞时不会时源主机的发送速率降低，对于实时应用（比如视频会议）是很重要的
5.支持一对一，一对多，多对一，多对多的交互通信
6.首部开销小，8字节（TCP20字节）
首部格式：4个字段，每个字段都是2字节，包括源端口、目的端口、长度、校验和

TCP主要特点
1.TCP提供面向连接的服务，数据传送前建立连接，传送后释放连接
2.TCP连接只能有两个端点，即点对点，不提供广播或多播服务
3.提供可靠交付的服务，通过TCP连接传送的数据，无差错，不丢失，无重复，按序到达
4.提供全双工通信，允许通信双方在任何时候发送数据，连接的两端都有发送和接收缓存。发送时，应用把数据传送给TCP缓存后，TCP会在合适的时机发送；接受时，TCP把收到的数据放入缓存，应用在合适的时候读取缓存
5.面向字节流。TCP的流（stream）指的是流入到进程或从进程流出的字节序列。虽然应用和TCP交互是一次一个大小不等的数据块，但TCP把它看成一连串无结构的字节流，且无法理解其含义。TCP不保证接受和发送方的数据块有对应大小的关系，比如发送了10个数据块，但接收方用4个数据块就全部接收。接收方和发送方的字节流必须完全一样。TCP会根据窗口值和网络拥塞情况决定一个报文段包含多少字节，比如应用给TCP的缓存的数据块太长，则TCP将其划分短一些再发送；若应用指发来一个字节，则TCP也可以等待字节足够多后再发送

TCP的连接
TCP把链接作为最基本的抽象。TCP连接的端点不是IP不是端口，而是套接字或者插口。套接字=IP:端口

停止等待协议
不管在第几层，都把传送的数据单元称为分组。停止等待就是每发送完一个分组就停止发送，等待对方的确认。收到确认后发送下一个分组
出现差错
A向B发送数据，B检测出了差错就丢弃，或者B根本就没收到，都会导致B不发送信息。A在一定时间内没有收到确认，就重发，这种叫做超时重传，在每发送一个分组后就设置一个超时定时器，收到确认后取消定时器
注意点：1.A在发送完分组后要暂时保留副本，以免重传  2.分组和确认分组必须有编号，才能知道哪个分组收到确认，哪个没有收到  3.超时重传时间理论上应比分组传输的平均往返时间更长一点
确认丢失和确认迟到
B对A发送的确认丢失了，A重传，B收到重传的分组后，应动作如下：1.丢弃这个重复的分组，不向上层交付  2.向A发送确认，因为A没有收到确认
还有一种情况，B的确认没有丢失但迟到了，A重复发送了多次，并收到多个重复的确认，此时A直接丢弃重复的确认即可
通过上述的确认和重传机制，可以在不可靠的网络上实现可靠的通信，这种传输协议称为自动重传请求ARQ
停止等待协议的缺点是信道利用率太低，相当于串行，可通过连续发送多个数组来解决，即连续ARQ协议和滑动窗口协议

连续ARQ协议的基本概念
发送方维持一个发送窗口，窗口内的分组可以连续发送出去，不用等对方的确认。发送方每收到一个确认，就把发送窗口向前滑动一个分组的位置。接收方一般都采用累计确认的方式，即不必对收到的每个分组都确认，而是收到几个分组后，对按序到达的最后一个分组发送确认。如果发送方发了5个分组，中间的第四个丢失，接收方只能对前三个分组确认，发送方必须对后两个分组重传

TCP报文段的首部格式
TCP报文段首部的前20个字节是固定的，4n个字节是可选的。固定部分的意义如下
1.源端口和目的端口，各2字节
2.序号，4字节，序号到最大值后，重新归0。字节流中的每一个字节都按顺序编号。首部中的序号字段指本报文段发送的数据的第一个字节的序号。举例：某报文段的序号为301，携带的数据有100字节，则本报文段的数据的第一个字节的序号为301，最后一个字节的序号为400，下一个报文段的序号从401开始，即下一个报文段的序号为401。该字段有事也叫报文段序号
3.确认号，4字节，是期望收到对方下一个报文段的第一个数据字节的序号。举例：B收到了A的报文段，序号为501，长度200，则B正确收到了A发送的到序号700为止的数据。因此B期望收到A的下一个数据序号为701，因此B给A的确认报文段中确认好为701
4.数据偏移，4位，TCP的数据起始位置距离报文段的起始位置有多远，即首部的长度，有上限
5.保留，6位
此外还有6个控制位，说明报文段的性质（6-11）
6.紧急URG，=1时表示该报文段中有紧急数据，优先传送，不要按原来的排队顺序传送
7.确认ACK，=0时确认号无效，=1时确认号有效。TCP规定，在连接建立后所有传送的报文段都必须把ACK置1
8.推送PSH，当两个应用进行交互时，有时希望在输入一个命令后马上收到对方的响应，发送方TCP把PSH置1，并创建报文发送，接收方TCP收到PSH=1的报文段就尽快交付给应用，而不是等缓存满了才交付。实际很少使用
9.复位RST，=1时表示TCP连接出现严重差错，比如主机崩溃，必须释放连接，再重建连接。此外还可用来拒绝一个非法的报文端或拒绝打开一个连接
10.同步SYN，在连接建立时用来同步序号。SYN=1且ACK=0，表示这是连接请求；若同意，则响应的报文段中SYN=ACK=1
11.终止FIN，=1时表示发送方的数据已发送完毕，并要求释放连接
12.窗口，2字节，接收方的缓存有限，通过该字段告诉发送方可接收的字节大小，发送方在发送数据时必须考虑这一点
13.校验和，2字节
14.紧急指针，2字节，当URG=1时才有效。紧急数据在前，普通数据在后，该字段指出了紧急数据的字节数，即紧急数据的末尾在报文段中的位置
15.选项，不定长，最多40字节，没有该项时TCP首部长度20字节

以字节为单位的滑动窗口
假设A给B发数据，A收到了B的确认报文段，其中窗口是20字节，确认号是31（即序号30及之前的数据都接收到了，接下来从31开始传），根据这两个数据，A就能构造出自己的发送窗口
后沿                                          前沿
->前移      |<-    A的发送窗口=20    ->|
30          31          32      ...  50       51

先讨论A的发送窗口
发送窗口表示，在没有收到B确认的情况下，A可以连续把窗口内的数据都发送出去，发送过的数据，在未收到确认前都必须咱领，以便超时重传时使用。A的发送窗口不能超过B的接收窗口的数值
发送窗口的位置由后沿和前沿共同决定，后沿只可能不动（没有收到新的确认）或前移（收到新的确认），无法后移（这意味着撤销）
前沿通常不断前移，也可能不动（没有收到新的确认或收到确认但对方通知的窗口缩小）。前沿也可能向后收缩，比如对方的通知窗口缩小，但TCP标准强烈不赞成这么做
现在假设A发送了序号为31-41的数据，此时发送窗口位置不变，但发送窗口靠后的11个字节表示已发送但未确认，靠前的9个字节是允许发送但尚未发送的
|<-                 A的发送窗口位置不变              ->|
31      ...  41     42          ...                 50      51
p1   已发送未确认    p2       允许发送但未发送                p3      不允许发送

可以看出，需要p1,p2,p3 三个指针来描述发送窗口的状态
p3-p1=A的发送窗口
p2-p1=已发送但未收到确认的字节数
p3-p2=允许发送但未发送的字节数，又称可用窗口或有效窗口

再看B的接收窗口
            |<-         B的接收窗口      ->|
30          31  【32】  【33】  34...     50   51
没有p2指针，【】表示已接收。B收到了32和33的数据，这些数据没有按序到达，因为31没有收到（丢失或在网络滞留），B只能对按序收到的数据中的最高序号给出确认，因此B的确认号仍是31
随后B收到31的数据并把31-33的数据交付给主机，然后删除这些数据，接收窗口前移3个序号，给A发送确认。此时确认号为34，窗口仍为20（数据没有接收完）
A收到B的确认后，p1移到34，p2不动，可用窗口变大了（42-53）

发送应用程序
                   |               发送缓存             |（发送程序最后写入的字节）
（最后被确认的字节）   | 发送窗口（已发送未确认+未发送）|
发送缓存用来暂时存放：1.应用程序给TCP准备发送的数据 2.TCP已发送但未收到确认的数据
发送窗口通常只是发送缓存的一部分，已确认的数据应当从发送缓存中删除，因此发送缓存和发送窗口的后沿是重合的。最后写入的字节-最后被确认的字节=发送缓存中的字节数

接收应用程序
                        |           接收缓存        |
     （下一个读取的字节）   |按序到达的数据|接收窗口      |
接收缓存用来暂时存放：1.按序到达的，尚未被接收应用程序读取的数据 2.未按序到达的数据
如果程序读取速度慢，接收窗口就会减小至0；读取速度快，接收窗口变大，但不能超过接收缓存

A的发送窗口是根据B的接收窗口设置的，但两者不一定一样大，比如网络拥塞时A会减小发送窗口值
对于不按序到达的数据，TCP未规定如何处理。如果接收方一律丢弃，则实现简单但发送方会重复传送大量数据，因此无序数据一般先临时存放在接窗口中，等缺少的字节收到后，再交付给上层的应用
TCP要求接收方必须有累计确认的功能，可以在合适时发送确认，也可以在发送数据时顺带携带上（这种情况很少）。接收方不应过分推迟发送确认（TCP规定不超过0.5秒）
TCP是全双工通信，双方都有自己的发送和接收窗口，切勿混淆

超时重传时间的选择
TCP采用了自适应算法，记录一个报文段发出的时间，以及收到确认的时间，时间差为报文段的往返时间RTT，以此计算加权平均往返时间RTTs，公式为：新RTTs=（1-a）*旧RTTs+a*新RTT，a建议为0.125
超时重传时间RTO应略大于RTTs，公式为：RTO=RTTs+4*RTTd，其中RTTd为RTT的偏差的加权平均值，公式为：新RTTd=（1-b）*旧RTTd+b*|RTTs-新RTT|，b建议为0.25
RTT的测量实现起来很复杂，比如超时重传后收到了确认，则无法分辨该确认是针对重传前还是后的，因为报文段完全一样，故若报文段进行了重传，则计算RTTs时忽略。但又带来了新问题：若报文段的时延突然增大很多，会发生大量重传（超时时间还是很小的），但重传的样本又被舍弃，因此改进：每重传一次，超时时间RTO就*2，不重传时，才根据RTO=RTTs+4*RTTd计算

选择确认SACK
收到的报文段无差错，但未按序号，即中间数据丢失，要设法做到只重传丢失的数据，已正确接收的不用重传。方法即为SACK（Selective ACK）
举例：已接收下列连续字节流：[1,1000],[1501,3000],[3501,4500]，确认号为1001。可以看到，1001-1500和3001-3500这两部分的字节块丢失，只要告诉发送方已接收的字节块的边界即可：1501,3001,3501,4501。TCP首部没有字段保存，所以放在【选项】中，由于选项的长度有限，所以最多只能报告4个字节块的边界信息。大多数的重传机制还是重传所有未被确认的数据块

TCP的流量控制
控制发送方的发送速率，让接收方及时接收。利用滑动窗口可以实现流量控制。当接收方的接收窗口为0时，就不允许发送方发送数据了，直到窗口不为0并通知发送方。再考虑一种情况：B向A发送了零窗口的报文段，B的接收缓存又有了空间，B向A发接收窗口=400的报文段，但该报文段丢失，A一直等待B的非零窗口通知，B一直等待A发送的数据，从而出现死锁。解决方案：TCP为每个连接设置持续计时器，一方收到了零窗口通知，就开启该计时器，到期时发送零窗口探测报文段（仅携带1字节的数据），对方在确认这个探测报文段时给出目前的窗口值，若为=0，那么重新开启计时器；不为0，则死锁就打破了

TCP的传输效率
应用把数据传送给TCP的发送缓存后，剩下的事就由TCP来完成。可以用不同机制来控制报文段的发送时机，比如当缓存中的数据达到最大报文段长度MSS字节时，就组装成TCP报文段发送；也可以是发送方的计时器到期时，就把现有的缓存数据组装发送。在TCP的实现中广泛使用Nagle算法：应用把数据发送至发送缓存，发送方把第一个数据字节发送，后面的缓存起来，等到收到确认后，再把现有的缓存全部组装发送，后续同理，即只有收到对前一个报文段的确认后才发送下一个报文段，此外当缓存数据达到发送窗口的一半或报文段的最大长度时，立即发送

TCP的拥塞控制
计算机网络中的链路容量（带宽）、交换节点中的缓存和处理机等，都是网络的资源。在某段时间，若对网络中的某一资源的需求超过了该资源所能提供的可用部分，网络的性能就会变差，称为拥塞。简单地增加资源不但不能解决问题，还会让网络的性能更差
举例：某节点缓存太小，大量分组被丢弃，若扩大缓存，但带宽和处理机速度未提高，则节点的缓存队列中的分组的等待时间将大大增加，上层软件只能进行重传。同理，只将处理器的速度提高，则其他地方又会出现瓶颈。问题的实质是整个系统的各个部分不匹配

拥塞控制就是防止过多的数据注入到网络中，这样可以使网络中的路由器或链路不致过载。流量控制往往是指点对点通信量的控制，是端到端的问题
TCP进行拥塞控制的算法有四种：【慢开始】，【拥塞避免】，【快重传】，【快恢复】。我们先假设接收方有足够大的缓存空间

下面讨论基于窗口的拥塞控制。发送方维持一个拥塞窗口（cwnd），其大小取决于网络的拥塞程度，且动态变化。发送方让自己的发送窗口等于拥塞窗口。原则上，只要网络没有出现拥塞，则拥塞窗口就可以增大一些；若出现拥塞或可能出现拥塞，则把拥塞窗口减小。网络拥塞时，路由器就丢弃分组，因此判断网络是否发生拥塞的依据是，发送方是否有收到确认报文，即是否超时（现在通信网络的传输质量都很好，因传输出差错而丢弃分组的概率很小）

【慢开始】算法的思路如下：主机发送数据时，不清楚网络的负荷情况，若立即传输大量数据，就可能引发拥塞，因此从小到大逐渐增大拥塞窗口数值。刚开始发送报文时，把拥塞窗口设置为初始值（和发送方的最大报文段SMSS有关），每收到一个对新的报文段的确认，就可以把拥塞窗口增大最多一个SMSS的数值（具体来说是min(N,SMSS),N为确认报文段确认的字节数）
举例：（虽然实际上TCP是用字节数作为窗口大小的单位，但为了方便起见，我们使用报文段的个数作为窗口大小的单位）一开始cwnd=1，发送第一个报文段M1，收到M1的确认后，cwnd=1+1=2。继续发送M2和M3并收到确认，即cwnd=2+2。下次发送M4-M7共4个报文段。由此可见，没经过一个【传输轮次】，cwnd就加倍。传输轮次经历的时间就是往返时间RTT，即把拥塞窗口允许发送的报文段全都发送，并收到发送的最后一个字节的确认的时间。慢开始的慢，不是指cwnd的增长速率慢，而是一开始cwnd=1，只能发送一个报文，相比设置大的cwnd要慢。TCP的实际运行中，发送方只要收到一个对新报文的确认，cwnd就立即+1，并发送新的报文段，而不用等待轮次中所有的确认都收到后才发送

【拥塞避免】为了防止拥塞窗口增大过快引起网络拥塞，需要设置一个慢开始门限（ssthresh），当cwnd<ssthresh，使用慢开始算法；cwnd=ssthresh，可使用慢开始也可使用拥塞避免算法；cwnd>ssthresh，使用拥塞避免算法。拥塞避免算法的思路是让拥塞窗口缓慢增大，即每经过一个往返时间RTT就把拥塞窗口+1，而非翻倍。在拥塞避免阶段，发生超时，则门限值为原本的一半，同时设置拥塞窗口为1，进入慢开始阶段

【快重传】有时个别报文段在网络中丢失，但网络未发生阻塞，则发送方误认为网络发生了拥塞，开启了慢开始。采用快重传算法可以让发送方尽早知道发生了个别报文段的丢失
快重传要求接收方立即发送确认，而不是发送数据时顺带确认，收到了失序的报文段也要立即发出对已收到的报文段的重复确认
举例：发送方发送了M1和M2并收到了确认，继续发送M3和M4，假设接收方只收到了M4，则接收方本来可以什么都不做，但按照快重传的算法，接收方必须发出对M2的重复确认（2次）。发送方继续发送M5和M6，接收方收到后仍要发出对M2的确认。这样接收方一共收到了4个对M2的确认，其中后面3个都是重复确认。按照快重传的算法，发送方只要连续收到3个重复确认，就知道接收方确实没有收到M3，应该立即重传（即快重传），这样就不会出现超时，发送方也不会误认为网络出现了拥塞

【快恢复】发送方现在知道只是丢失了个别的报文段，于是不启动慢开始，而是执行快恢复算法：发送方调整门限制ssthresh=cwnd/2，并设置拥塞窗口cwnd=ssthresh，并开始执行【拥塞避免】算法

从上面可知，在拥塞避免阶段，拥塞窗口是按线性增大的，称为加法增大AI（Additive Increase），一旦出现超时或3个重复确认，就把门限值设置为当前拥塞窗口的一半，并大大减小拥塞窗口的数值，称为乘法减小MD（Multiplicative Decrease）
上面都是假设接收方缓存足够大。当缓存有限时，接收方根据自己的接收能力设定了接收方窗口rwnd（又称通知窗口），并把这个值写入TCP首部，返回给发送方。从接收方对发送方的流量控制的角度考虑，发送方的发送窗口一定不能超过接收方给出的接收窗口值，即发送方窗口的上限=min（rwnd，cwnd）


TCP三次握手
第一次：客户端->服务器，SYN=1，选择一个初始序号seq=x。TCP规定SYN=1的报文段不能携带数据，但要消耗一个序号。客户端进入SYN-SENT状态
第二次：服务器->客户端，SYN=ACK=1，确认号ack=x+1，选择一个初始序号seq=y。该报文不能携带数据，要消耗一个序号。服务端进入SYN-RCVD状态
第三次：客户端->服务器，ACK=1，确认号ack=y+1，序号seq=x+1。ACK报文段可以携带数据，如果不携带则不消耗序号，此时下一个报文段的序号仍是seq=x+1。客户端进入ESTABLISHED状态
其中第二次握手也可拆分为两个报文段：1.发送确认报文段，ACK=1，ack=x+1 2.发送同步报文段，SYN=1，seq=y。则变成四次握手，但效果是一样的
为何需要三次握手
由于网络不稳定，发送的TCP包可能经过很长时间才能到达，客户端会重传，之后旧的TCP包到达。如果没有三次握手，服务器会以为这是新发起的一个请求，并建立连接。有了三次握手，服务器会向客户端确认，由于客户端并没有真的发起请求，所以不会理会，避免了建立连接
半连接队列：服务器收到第一次握手的TCP报文时，在半连接队列中创建一个条目，此时连接处于SYN_RCVD状态。队列满时，可能会丢弃后续的TCP报文，或采取其他策略，如调整队列大小
全连接队列：三次握手成功后连接从半连接队列转移至全连接队列

TCP四次挥手
第一次：A-B，FIN=1，序号seq=u，它等于前面已传送过的数据的最后一个字节的序号+1，A进入FIN-WAIT-1状态。FIN报文段即使不携带数据，也要消耗一个序号
第二次：B-A，ACK=1，ack=u+1，seq=v，它等于B已传送过的数据的最后一个字节的序号+1，B进入CLOSE-WAIT状态。此时TCP应通知应用，因为A->B这个方向的连接已释放，TCP连接处于半关闭状态，即A没有数据要发送了，但若B要发送数据，A仍要接收。也就是说，B->A这个方向的连接未关闭，这个状态可能持续一段时间
A收到B的确认后，进入FIN-WAIT-2状态，等待B发出的连接释放报文段
第三次：B-A，FIN=1，ACK=1，seq=w（半关闭状态B可能又发送了数据），ack=u+1，B进入LAST-ACK状态，等待A的确认
第四次：A-B，ACK=1，ack=w+1，seq=u+1，A进入TIME-WAIT状态，此时TCP连接还未释放。经过时间等待计时器设置的时间2*MSL后，A才进入CLOSED状态。MSL为最长报文段寿命
为何必须等待2MSL的时间？
1.保证A发送的最后一个ACK报文段（即第四次挥手）能够到达B，这个ACK报文段可能丢失，导致B收不到第三次挥手的确认，B会重传第三次挥手的报文段，则A就能在2MSL的时间内收到该报文段，然后A再次进行第四次挥手，重启计时器，最后AB都进入CLOSED状态，否则B无法正常进入CLOSED状态
2.防止已失效的报文段出现在本连接中。第四次挥手后，A再等待2MSL，就可以使本次连接所有的报文段都从网络中消失，可以使下一个新的连接中不出现旧的连接的报文段

TCP还有一个保活计时器keepalive timer。A与B建立了连接，A挂了，需要有措施保证B不会白等，方案就是保活计时器。服务端每收到一次客户端的数据，就重置该计时器，时间设置通常为2小时，若2小时内没有收到客户的数据，则服务端发送一个探测报文段，随后每75秒发送一次，若连续10都无响应，则服务端断开连接

TCP拆包和粘包
UDP是没有拆包和粘包的，因为UDP是有数据边界的。而TCP是流，没有数据边界
拆包：TCP发送长消息时，拆成多个小的数据报，接收方合并
粘包：TCP高频发送小数据时，合并成一个数据报，接收方拆分
如何解决拆包和粘包问题：
主要是应用层解决
1.应用层将包的大小固定，如果不足则填充空格（主要解决拆包的问题）
2.在包的末尾添加分隔符（粘包和拆包都能解决）
3.将消息分为header和body，header中保存了消息的总长度（粘包和拆包都能解决，且最常见）

========================应用层========================

域名系统DNS
叫做域名而非名字是因为互联网的命名系统中使用了许多的域。DNS被设计为联机分布式数据库系统，采用客户服务器方式。大多数名字都在本地进行解析，仅少量需要在互联网通信
DNS解析过程的要点：应用调用解析程序，成为DNS的客户，把要解析的域名放在DNS请求报文中，以UDP用户数据报的方式发给本地域名服务器。本地域名服务器查找后，把IP放在回答报文中返回。若本地域名服务器不能回答该请求，则暂时成为DNS的另一个客户，向其他域名服务器发出询问，重复此过程直到找到能够回答该请求的域名服务器为止

域名结构
早期的互联网使用了非等级的名字空间，当集合很大且经常变化时难以管理，后来就采用了层次树状结构的命名方法，任何一个连接到互联网的主机或路由器，都有一个唯一的层次结构的名字，即域名。域可以划分子域，子域可继续划分，形成了顶级域、二级域、三级域等。它实际上是一个倒过来的树：
                                根
顶级域名            com                     net     gov     cn
二级域名        cctv        ibm
三级域名    mail    www

DNS规定，域名不区分大小写，允许的标点符号只有-，级别最低的域名写在左边，级别最高的写在右边
理论上，可以让域名的树的每个节点对应一个域名服务器，但那样会导致域名服务器太多，DNS采用划分区的方法来解决（相当于把树拆成多个分支）
一个服务器负责管辖的范围叫做区，一个区内的所有节点必须相同，每个区设置相应的权限域名服务器，区可能小于等于域，但不能大于域
比如域为abc.com，只设置一个区abc.com，则区abc.com和域abc.com是相同的；若区分为abc.com和y.abc.com，则两个区都属于域abc.com，都要设置权限域名服务器

域名服务器划分为四种类型
1.根域名服务器，是最高层，最重要的域名服务器，所有的根域名服务器都知道所有的顶级域名服务器的域名和IP地址。全球在588个地点（2016.2）安装了根域名服务器，但只使用了13个不同的域名（a.rootservers.net,b.rootservers.net,....），即多个根域名服务器使用同一个域名。世界上大部分DNS域名服务器，都能就近找到根域名服务器（根域名服务器采用了任播技术，任播的IP数据报的终点主机在不同地点，但具有相同IP地址，IP数据报交付离源点最近的一台主机）
2.顶级域名服务器，负责管理在该顶级域名服务器注册的所有二级域名
3.权限域名服务器，即上面负责一个区的域名服务器，当权限域名服务器无法回答时，就会告诉客户下一步应查找哪个权限域名服务器
4.本地域名服务器，不属于上面树的层次结构，但很重要，主机发出DNS查询请求时，这个请求就会发给本地域名服务器

DNS域名服务器会把数据复制到几个域名服务器来保存，其中一个为主域名服务器，其他为辅助域名服务器。当主出故障时，辅助可以保证查询不会中断。主定期把数据复制到辅助，数据更改只能在主中进行

解析过程
主机向本地域名服务器的查询一般采用递归查询，即若本地域名服务器不知道查询域名的IP，则向其他根域名服务器发出查询请求。根收到请求后，要么直接给出IP地址，要么告诉本地域名服务器应该查询哪个域名服务器（通常是顶级域名服务器），而非替本地域名服务器查询。同理，顶级域名服务器要么给出要查询的IP，要么告诉本地域名服务器应查询哪个权限域名服务器
域名服务器广泛使用了高速缓存，本地域名服务器和主机都有使用

远程终端协议TELNET
telnet是远程终端协议，是互联网标准，用户用telnet就可通过TCP连接注册（登录）到远程的另一个主机（使用主机名或IP地址）。telnet能将用户的点击传到远程主机，也能将远程主机的数据返回到用户屏幕，因此也称为终端仿真协议

万维网WWW
万维网是大规模、联机式的信息储藏所。是一个分布式的超媒体系统，是超文本系统的扩充。超文本是指包含指向其他文档的链接（也叫超链）的文本，即一个超文本由多个信息源链接成，这些信息源可以分布在世界各地，且数目不受限制
超媒体和超文本的区别是文档内容不同，超文本文档仅包含文本信息，超媒体文档还包含其他表示形式的信息，如图像、声音、动画等

统一资源定位符URL
标识万维网上的各种文档，使每个文档在整个互联网的范围内都具有唯一的标识符URL。一般由以下四个部分组成：协议://主机:端口/路径

超文本传送协议HTTP
要实现万维网上的各种链接，就使用HTTP协议，它是一个应用层协议。HTTP是面向事务的应用层协议。每个万维网网点都有一个服务器进程，不断监听TCP的80端口，以便发现是否有浏览器（即万维网客户，这俩是同义词）像它发出连接建立请求。HTTP使用了TCP协议，不考虑数据传输过程中丢失了要如何重传。HTTP协议是无连接的，即通信双方在交换HTTP报文之前不需要先建立HTTP连接。HTTP在建立TCP连接时，当前两次握手完成后（即经过一个RTT时间），浏览器就把HTTP请求报文作为第三次握手的报文数据，发送给服务器。
HTTP/1.0的主要缺点，就是请求一个万维网文档所需的时间较长，为文档传输时间+2*RTT。此外浏览器和服务器每一次建立新的TCP连接都要分配缓存和变量。这种非持续连接是的服务器负担很重
HTTP/1.1使用了持续连接，即服务器在返回响应后仍在一段时间内保存这条连接，使得同一个浏览器和服务器可以继续使用该连接收发报文。持续连接有两种工作方式：非流水线和流水线。非流水线方式指客户在收到前一个响应后才能发出下一个请求；流水线方式指客户在收到HTTP响应报文前就可以发送新的请求报文

代理服务器
一种网路实体，又称为万维网高速缓存，把最近的请求及响应暂存在本地磁盘中，缓存命中则直接返回。可工作在客户端或服务端，也可在中间系统上工作

HTTP的报文结构
有请求报文和响应报文两种。由于HTTP是面向文本的，报文中的每一个字段都是ASCII码
请求和响应报文都是由三部分组成
开始行，请求报文的开始行叫做请求行，响应报文的开始行叫做状态行
首部行
实体主体

请求行只有三个内容：方法，URL，HTTP版本。示例
GET http://www.abc.com/dir/index.html HTTP/1.1

下面是一个完整的HTTP请求报文的示例
GET /dir/index.html HTTP/1.1
HOST: www.abc.com
Connection: close
User-Agent: Mozilla/5.0
Accept-Language: cn

请求行使用了相对URL，因为下面的首部行（第二行）给出了主机的域名
第三行是告诉服务器不使用持续连接，浏览器希望服务器在传送完所请求的对象后关闭TCP连接

状态码包括三项：HTTP版本，状态码，状态码的简单解释。示例
HTTP/1.1 202 Accepted

1xx：通知信息，如请求收到了或正在处理
2xx：成功，如接受或知道了
3xx：重定向
4xx：客户的差错，如请求有错误的语法或不能完成
5xx：服务器的差错，如服务器失效无法完成请求

在服务器上存放用户的信息
有时服务器需要记住用户的身份，可以在HTTP中使用Cookie来做到这点。用户A在访问某个使用Cookie的网站时，服务器就为A产生一个唯一的识别码，在给A的响应报文的首部行中，添加如下
Set-cookie: xxxxxx
A收到响应后，就在浏览器中暂存服务器的主机名及cookie值，当A继续浏览网站时，发送的每个HTTP请求报文都携带这个识别码，放在请求报文的首部行中
Cookie: xxxxxx
于是，网站就可以跟踪A的活动

动态主机配置协议DHCP
连接到互联网的计算机需要的配置信息包括：IP地址、子网掩码、默认路由器的IP地址、域名服务器的IP地址。DHCP协议允许一台计算机加入新的网络和获取IP地址而不用手工参与
DHCP对客户和服务器都使用。当客户端计算器移至新网络时，可使用DHCP获取其配置信息而不需要手工干预。DHCP给位置固定的服务器指派一个永久地址，当服务器重启时地址不变
需要IP地址的主机在启动时向DHCP服务器【广播】发送发现报文（DHCPDISCOVER，目的IP全为1，即255.255.255.255），这是该主机就成为DHCP客户，源IP设置为全0。这样本地网络上的所有主机都能接收到这个广播报文，但只有DHCP服务器才会响应。DHCP服务器在其数据库中查询该计算机的配置信息，存在则返回，不存在则从IP地址池中取一个地址分配给该计算机，DHCP服务器的回答报文叫做提供报文（DHCPOFFER），表示提供IP地址等配置信息
但很多时候不会在每一个网络内都配置一个DHCP服务器，而是每个网络至少有一个DHCP中继代理（通常是路由器），它配置了DHCP服务器的IP地址。当中继代理收到主机A的广播后，以单播方式向DHCP服务器转发报文
DHCP报文只是UDP用户数据报的数据，还要添加UDP首部、IP数据报首部，以太网MAC帧首部和尾部，才能在链路上传送
DHCP分配给DHCP客户的IP地址是临时的，称为租用期，时间由DHCP服务器决定
DHCP客户使用的UDP端口号为68，DHCP服务器使用的UDP端口是67，都是熟知端口
DHCP很适合经常移动位置的计算机

过程示例
1.DHCP服务器监听67端口
2.DHCP客户通过68端口发送DHCP发现报文
3.多个DHCP服务器都会收到该报文并回复DHCP提供报文（提供报文中已经包含了IP）
4.DHCP客户选择一个，并发送DHCP请求报文
5.选择的DHCP服务器发送确认报文DHCPACK。从现在起，DHCP就可以使用该IP地址了，处于已绑定状态（DHCP客户的IP地址和硬件地址已绑定），根据服务器提供的租用期T设置两个计时器T1（0.5T）和T2（0.875T）
6.T1时间到，发送DHCP请求报文更新T
7.服务器若同意，则返回DHCPACK，客户重置计时器
8.不同意则返回DHCPNACK，客户必须立即停止使用原来的IP地址，重新申请IP。若DHCP服务器不响应步骤6的请求报文，则T2时间到时DHCP重新发送请求报文
9.DHCP客户可以随时终止租用期，发送释放报文DHCPRELEASE即可

========================安全========================

传统手写签名有两个作用
1.证明签名者的身份（笔迹鉴定）2.表明签名者认可签名的内容（肉眼观察）。数字签名有同样的作用，但实现方式不同：1.使用数字证书证明身份2.对比文件hash值

数字签名
签名过程：小明对明文计算摘要（sha256），然后用私钥加密得到密文，将明文、密文、公钥一同发布到互联网。计算摘要是为了提高效率，同时有些算法无法处理太长的明文
验证过程：小红用公钥解密，得到摘要A，对明文计算摘要得到B，比较AB是否相等
缺陷：数字签名可以保证内容不被篡改，但无法保证公钥为小明创建的

数字证书
作用是证明公钥的生成者为小明。小明将公钥及身份信息发给权威的CA机构，CA颁发给小明一个证书，其中包含了公钥和身份信息，并用CA私钥加密。小明将证书发布到互联网，小红就可以通过CA公钥证明哪个证书是小明的，从而确定公钥
如何保证数字证书不是伪造？数字证书由CA签名，CA有自己的公私钥，每人的电脑里有CA根证书，放在浏览器或操作系统里，记录了可信赖的CA机构信息及公钥

https
tcp连接创立后进入https的加密流程。流程：1.TLS通过4次握手获取会话秘钥 2.基于秘钥进行对称加密通信
四次握手：
1.客户端发送给服务端，包括支持什么加密协议版本、 算法及一个随机数A
2.服务端发给服务端，具体的加密方式、服务器证书、随机数B
3.客户端从证书中取得服务器公钥，生成随机数C，用公钥对C加密发给服务端。客户端用ABC计算得到会话秘钥，将迄今为止的通信数据算一个摘要（也叫finished报文），用会话秘钥加密发给服务端做校验
4.服务端使用服务器私钥解密，得到C，对ABC使用同样的算法得到会话秘钥，同样对迄今为止的数据算摘要发给客户端做校验
后续双方就使用这个会话秘钥进行对称加密通信。不使用非对称加密是因为慢；使用3个随机数是为了加大随机性，使秘钥更难被破解

自己签名的不受信任证书要安装在客户端

https不是绝对安全的，https只能解决端到端的传输安全问题，如果客户端本身已经被入侵，即端已经被入侵，并被安装了伪造的根证书，那https也是不安全的
